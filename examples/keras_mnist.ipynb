{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib \n",
    "matplotlib.use('Agg') \n",
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_logs(history):\n",
    "    evaluation_cost = history.history['val_loss']\n",
    "    evaluation_accuracy = history.history['val_acc']\n",
    "    training_cost = history.history['loss']\n",
    "    training_accuracy = history.history['acc']\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    f.set_figwidth(10)\n",
    "    ax1.plot(evaluation_cost,label= 'test')\n",
    "    ax1.plot(training_cost, label='train')\n",
    "    ax1.set_title('Cost')\n",
    "    ax1.legend()\n",
    "    ax2.plot(evaluation_accuracy, label='test')\n",
    "    ax2.plot(training_accuracy, label='train')\n",
    "    ax2.set_title('Accuracy')\n",
    "    ax2.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "class WeightsHistory(keras.callbacks.Callback):\n",
    "  \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(epoch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 train samples\n",
      "10000 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 30)                23550     \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 23,860\n",
      "Trainable params: 23,860\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "7s - loss: 0.5129 - acc: 0.8774 - val_loss: 0.2651 - val_acc: 0.9225\n",
      "28.012\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "9s - loss: 0.2459 - acc: 0.9263 - val_loss: 0.2203 - val_acc: 0.9357\n",
      "12.5559\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "9s - loss: 0.2105 - acc: 0.9377 - val_loss: 0.2043 - val_acc: 0.9416\n",
      "10.0203\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "9s - loss: 0.1912 - acc: 0.9442 - val_loss: 0.1881 - val_acc: 0.9461\n",
      "8.59475\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "9s - loss: 0.1778 - acc: 0.9486 - val_loss: 0.1870 - val_acc: 0.9463\n",
      "7.56954\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "8s - loss: 0.1689 - acc: 0.9512 - val_loss: 0.1792 - val_acc: 0.9486\n",
      "6.84041\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "8s - loss: 0.1614 - acc: 0.9527 - val_loss: 0.1784 - val_acc: 0.9494\n",
      "6.21747\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "8s - loss: 0.1549 - acc: 0.9553 - val_loss: 0.1789 - val_acc: 0.9514\n",
      "5.85192\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "9s - loss: 0.1508 - acc: 0.9569 - val_loss: 0.1771 - val_acc: 0.9518\n",
      "5.51758\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10s - loss: 0.1471 - acc: 0.9577 - val_loss: 0.1759 - val_acc: 0.9518\n",
      "5.24713\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "8s - loss: 0.1428 - acc: 0.9596 - val_loss: 0.1737 - val_acc: 0.9522\n",
      "5.08803\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "11s - loss: 0.1395 - acc: 0.9609 - val_loss: 0.1778 - val_acc: 0.9527\n",
      "4.79229\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10s - loss: 0.1369 - acc: 0.9608 - val_loss: 0.1811 - val_acc: 0.9510\n",
      "4.80223\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "9s - loss: 0.1344 - acc: 0.9623 - val_loss: 0.1766 - val_acc: 0.9534\n",
      "4.61215\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10s - loss: 0.1324 - acc: 0.9629 - val_loss: 0.1740 - val_acc: 0.9542\n",
      "4.37692\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "8s - loss: 0.1307 - acc: 0.9635 - val_loss: 0.1723 - val_acc: 0.9546\n",
      "4.27865\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10s - loss: 0.1290 - acc: 0.9649 - val_loss: 0.1759 - val_acc: 0.9545\n",
      "4.19691\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "9s - loss: 0.1280 - acc: 0.9646 - val_loss: 0.1761 - val_acc: 0.9542\n",
      "4.14845\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "9s - loss: 0.1261 - acc: 0.9657 - val_loss: 0.1794 - val_acc: 0.9542\n",
      "3.99344\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "9s - loss: 0.1262 - acc: 0.9657 - val_loss: 0.1796 - val_acc: 0.9544\n",
      "3.89848\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10s - loss: 0.1253 - acc: 0.9661 - val_loss: 0.1801 - val_acc: 0.9536\n",
      "3.9087\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "8s - loss: 0.1232 - acc: 0.9669 - val_loss: 0.1816 - val_acc: 0.9545\n",
      "3.7815\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "9s - loss: 0.1230 - acc: 0.9675 - val_loss: 0.1828 - val_acc: 0.9525\n",
      "3.72522\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "8s - loss: 0.1222 - acc: 0.9672 - val_loss: 0.1830 - val_acc: 0.9536\n",
      "3.69104\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "9s - loss: 0.1210 - acc: 0.9681 - val_loss: 0.1813 - val_acc: 0.9543\n",
      "3.68623\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "11s - loss: 0.1211 - acc: 0.9680 - val_loss: 0.1831 - val_acc: 0.9545\n",
      "3.6417\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "9s - loss: 0.1194 - acc: 0.9683 - val_loss: 0.1861 - val_acc: 0.9534\n",
      "3.64306\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "9s - loss: 0.1194 - acc: 0.9688 - val_loss: 0.1910 - val_acc: 0.9538\n",
      "3.62599\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10s - loss: 0.1184 - acc: 0.9687 - val_loss: 0.1897 - val_acc: 0.9548\n",
      "3.50313\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10s - loss: 0.0816 - acc: 0.6911 - val_loss: 1.1921e-07 - val_acc: 0.0980\n",
      "nan\n",
      "Test score: 1.19209303762e-07\n",
      "Test accuracy: 0.098\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras import regularizers\n",
    "\n",
    "batch_size = 10\n",
    "nb_classes = 10\n",
    "nb_epoch = 30\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(60000, 784)[:50000,:]\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train[:50000], nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_shape=(784,))) # kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10)) # kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "n_np = numpy.array( model.get_weights()[0])\n",
    "for i in range(30):\n",
    "    o_np = n_np\n",
    "    model.fit(X_train, Y_train,\n",
    "                        batch_size=batch_size, epochs=1,\n",
    "                        verbose=2, validation_data=(X_test, Y_test))\n",
    "    score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    \n",
    "    n_np = numpy.array(model.get_weights()[0])\n",
    "    d_np = n_np - o_np\n",
    "    print(numpy.linalg.norm(d_np))\n",
    "    \n",
    "#    for weight in weights:\n",
    "#        print(len(weight))\n",
    "#    print(weights[3])\n",
    "    \n",
    "        \n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl0AAAEICAYAAABlKUHyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4D8Y3obWJvWiagAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f07ff553550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_logs(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
       " 'history': {'acc': [0.89661666676203411,\n",
       "   0.96811666669845586,\n",
       "   0.97623333339691165,\n",
       "   0.97990000006357825,\n",
       "   0.98135000003178918,\n",
       "   0.98255000003178916,\n",
       "   0.98321666673024499,\n",
       "   0.98338333336512251,\n",
       "   0.98430000009536744,\n",
       "   0.98363333339691161,\n",
       "   0.98533333333333328,\n",
       "   0.98404999999999998],\n",
       "  'loss': [0.3565979616324107,\n",
       "   0.10986235253810883,\n",
       "   0.08159195179541906,\n",
       "   0.070903886894385024,\n",
       "   0.065989336803555482,\n",
       "   0.062632201756536957,\n",
       "   0.059152580281098682,\n",
       "   0.059206081442286569,\n",
       "   0.0564329680763185,\n",
       "   0.060700366028149925,\n",
       "   0.056821525609493252,\n",
       "   0.059862820374965667],\n",
       "  'val_acc': [0.97829999999999995,\n",
       "   0.98660000000000003,\n",
       "   0.98560000000000003,\n",
       "   0.98829999999999996,\n",
       "   0.98839999999999995,\n",
       "   0.98899999999999999,\n",
       "   0.98980000000000001,\n",
       "   0.98809999999999998,\n",
       "   0.98999999999999999,\n",
       "   0.98980000000000001,\n",
       "   0.99050000000000005,\n",
       "   0.98999999999999999],\n",
       "  'val_loss': [0.067472899950668214,\n",
       "   0.041333292219042778,\n",
       "   0.041590222879499199,\n",
       "   0.036324407774303111,\n",
       "   0.034705902426992542,\n",
       "   0.038740440631570526,\n",
       "   0.031659034133178644,\n",
       "   0.035377736126352102,\n",
       "   0.033315802509296916,\n",
       "   0.033481110350830567,\n",
       "   0.031696927737380608,\n",
       "   0.038495748898375315]},\n",
       " 'model': <keras.models.Sequential at 0x7f07fc0aebe0>,\n",
       " 'params': {'batch_size': 128,\n",
       "  'do_validation': True,\n",
       "  'epochs': 12,\n",
       "  'metrics': ['loss', 'acc', 'val_loss', 'val_acc'],\n",
       "  'samples': 60000,\n",
       "  'steps': None,\n",
       "  'verbose': 2},\n",
       " 'validation_data': [array([[[[ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           ..., \n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.]],\n",
       "  \n",
       "          [[ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           ..., \n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.]],\n",
       "  \n",
       "          [[ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           ..., \n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.]],\n",
       "  \n",
       "          ..., \n",
       "          [[ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           ..., \n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.]],\n",
       "  \n",
       "          [[ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           ..., \n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.]],\n",
       "  \n",
       "          [[ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           ..., \n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.]]],\n",
       "  \n",
       "  \n",
       "         [[[ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           ..., \n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.]],\n",
       "  \n",
       "          [[ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           ..., \n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.]],\n",
       "  \n",
       "          [[ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           ..., \n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.]],\n",
       "  \n",
       "          ..., \n",
       "          [[ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           ..., \n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.]],\n",
       "  \n",
       "          [[ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           ..., \n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.]],\n",
       "  \n",
       "          [[ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           ..., \n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.]]],\n",
       "  \n",
       "  \n",
       "         [[[ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           ..., \n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.]],\n",
       "  \n",
       "          [[ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           ..., \n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.]],\n",
       "  \n",
       "          [[ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           ..., \n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.]],\n",
       "  \n",
       "          ..., \n",
       "          [[ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           ..., \n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.]],\n",
       "  \n",
       "          [[ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           ..., \n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.]],\n",
       "  \n",
       "          [[ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           ..., \n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.]]],\n",
       "  \n",
       "  \n",
       "         ..., \n",
       "         [[[ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           ..., \n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.]],\n",
       "  \n",
       "          [[ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           ..., \n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.]],\n",
       "  \n",
       "          [[ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           ..., \n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.]],\n",
       "  \n",
       "          ..., \n",
       "          [[ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           ..., \n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.]],\n",
       "  \n",
       "          [[ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           ..., \n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.]],\n",
       "  \n",
       "          [[ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           ..., \n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.]]],\n",
       "  \n",
       "  \n",
       "         [[[ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           ..., \n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.]],\n",
       "  \n",
       "          [[ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           ..., \n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.]],\n",
       "  \n",
       "          [[ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           ..., \n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.]],\n",
       "  \n",
       "          ..., \n",
       "          [[ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           ..., \n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.]],\n",
       "  \n",
       "          [[ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           ..., \n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.]],\n",
       "  \n",
       "          [[ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           ..., \n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.]]],\n",
       "  \n",
       "  \n",
       "         [[[ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           ..., \n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.]],\n",
       "  \n",
       "          [[ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           ..., \n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.]],\n",
       "  \n",
       "          [[ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           ..., \n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.]],\n",
       "  \n",
       "          ..., \n",
       "          [[ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           ..., \n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.]],\n",
       "  \n",
       "          [[ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           ..., \n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.]],\n",
       "  \n",
       "          [[ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           ..., \n",
       "           [ 0.],\n",
       "           [ 0.],\n",
       "           [ 0.]]]], dtype=float32),\n",
       "  array([[ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  0.,  0.,  0.]]),\n",
       "  array([ 1.,  1.,  1., ...,  1.,  1.,  1.], dtype=float32),\n",
       "  0.0]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## now with convolution layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/anaconda3/envs/dsretreat-s/lib/python3.6/site-packages/ipykernel_launcher.py:45: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1..., padding=\"valid\")`\n",
      "/home/diego/anaconda3/envs/dsretreat-s/lib/python3.6/site-packages/ipykernel_launcher.py:47: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "/home/diego/anaconda3/envs/dsretreat-s/lib/python3.6/site-packages/keras/models.py:848: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "3s - loss: 0.3566 - acc: 0.8966 - val_loss: 0.0675 - val_acc: 0.9783\n",
      "Epoch 2/12\n",
      "3s - loss: 0.1099 - acc: 0.9681 - val_loss: 0.0413 - val_acc: 0.9866\n",
      "Epoch 3/12\n",
      "3s - loss: 0.0816 - acc: 0.9762 - val_loss: 0.0416 - val_acc: 0.9856\n",
      "Epoch 4/12\n",
      "3s - loss: 0.0709 - acc: 0.9799 - val_loss: 0.0363 - val_acc: 0.9883\n",
      "Epoch 5/12\n",
      "3s - loss: 0.0660 - acc: 0.9814 - val_loss: 0.0347 - val_acc: 0.9884\n",
      "Epoch 6/12\n",
      "3s - loss: 0.0626 - acc: 0.9826 - val_loss: 0.0387 - val_acc: 0.9890\n",
      "Epoch 7/12\n",
      "3s - loss: 0.0592 - acc: 0.9832 - val_loss: 0.0317 - val_acc: 0.9898\n",
      "Epoch 8/12\n",
      "3s - loss: 0.0592 - acc: 0.9834 - val_loss: 0.0354 - val_acc: 0.9881\n",
      "Epoch 9/12\n",
      "3s - loss: 0.0564 - acc: 0.9843 - val_loss: 0.0333 - val_acc: 0.9900\n",
      "Epoch 10/12\n",
      "3s - loss: 0.0607 - acc: 0.9836 - val_loss: 0.0335 - val_acc: 0.9898\n",
      "Epoch 11/12\n",
      "3s - loss: 0.0568 - acc: 0.9853 - val_loss: 0.0317 - val_acc: 0.9905\n",
      "Epoch 12/12\n",
      "3s - loss: 0.0599 - acc: 0.9841 - val_loss: 0.0385 - val_acc: 0.9900\n",
      "Test score: 0.0384957463195\n",
      "Test accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "batch_size = 128\n",
    "nb_classes = 10\n",
    "nb_epoch = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "# convolution kernel size\n",
    "kernel_size = (3, 3)\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(nb_filters, kernel_size[0], kernel_size[1],\n",
    "                        border_mode='valid',\n",
    "                        input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(nb_filters, kernel_size[0], kernel_size[1]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "          verbose=2, validation_data=(X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/anaconda3/envs/dsretreat-s/lib/python3.6/site-packages/ipykernel_launcher.py:45: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1..., padding=\"valid\")`\n",
      "/home/diego/anaconda3/envs/dsretreat-s/lib/python3.6/site-packages/ipykernel_launcher.py:47: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "/home/diego/anaconda3/envs/dsretreat-s/lib/python3.6/site-packages/keras/models.py:848: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "3s - loss: 1.5899 - acc: 0.4826 - val_loss: 0.4338 - val_acc: 0.8840\n",
      "Epoch 2/12\n",
      "3s - loss: 0.6076 - acc: 0.8147 - val_loss: 0.2749 - val_acc: 0.9132\n",
      "Epoch 3/12\n",
      "3s - loss: 0.4586 - acc: 0.8607 - val_loss: 0.2222 - val_acc: 0.9332\n",
      "Epoch 4/12\n",
      "5s - loss: 0.4001 - acc: 0.8785 - val_loss: 0.1912 - val_acc: 0.9416\n",
      "Epoch 5/12\n",
      "3s - loss: 0.3606 - acc: 0.8937 - val_loss: 0.1775 - val_acc: 0.9446\n",
      "Epoch 6/12\n",
      "3s - loss: 0.3384 - acc: 0.8992 - val_loss: 0.1645 - val_acc: 0.9506\n",
      "Epoch 7/12\n",
      "3s - loss: 0.3166 - acc: 0.9044 - val_loss: 0.1527 - val_acc: 0.9531\n",
      "Epoch 8/12\n",
      "3s - loss: 0.2983 - acc: 0.9106 - val_loss: 0.1480 - val_acc: 0.9565\n",
      "Epoch 9/12\n",
      "3s - loss: 0.2807 - acc: 0.9161 - val_loss: 0.1345 - val_acc: 0.9574\n",
      "Epoch 10/12\n",
      "3s - loss: 0.2718 - acc: 0.9190 - val_loss: 0.1276 - val_acc: 0.9591\n",
      "Epoch 11/12\n",
      "3s - loss: 0.2595 - acc: 0.9224 - val_loss: 0.1271 - val_acc: 0.9613\n",
      "Epoch 12/12\n",
      "3s - loss: 0.2531 - acc: 0.9253 - val_loss: 0.1199 - val_acc: 0.9630\n",
      "Test score: 0.119862658735\n",
      "Test accuracy: 0.963\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "batch_size = 128\n",
    "nb_classes = 10\n",
    "nb_epoch = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "# convolution kernel size\n",
    "kernel_size = (3, 3)\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(nb_filters, kernel_size[0], kernel_size[1],\n",
    "                        border_mode='valid',\n",
    "                        input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='SGD',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "          verbose=2, validation_data=(X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl0AAAEICAYAAABlKUHyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzs3XmcXGWZ9//PVdXV+76kk05n6YSw\nhC1AABGioLIEkEUUMWQGxiX6QxkeFUd4RvARfw6MC8P4E1DQ/AAxIMKoOAQJYiIwgpBICEkgJOkE\n0uksnVTv6a2qrueP+1R3daeTrk4v1VV1vV+vetWps1RdFcLJt+5z3/cRVcUYY4wxxowtX6ILMMYY\nY4xJBxa6jDHGGGPGgYUuY4wxxphxYKHLGGOMMWYcWOgyxhhjjBkHFrqMMcYYY8aBhS5jjDHGmHFg\nocuMORFZJCKrRaRNRHaJyLMics4I3m+7iHxsNGs0xqQ2EVklIo0ikpXoWkz6stBlxpSIfA24B/g3\noBKYDtwHXJ7Iuowx6UNEZgILAAUuG8fPzRivzzLJwUKXGTMiUgTcAXxZVf9LVdtVtUdV/6Cq3xCR\nLBG5R0Tqvcc90V+hIlIuIv8tIk0iEhSRl0TEJyK/xAW3P3gtZ/+SyO9ojEkK/wi8CjwEXBddKSI5\nIvIjEXlPRJpF5GURyfG2nSMif/XOQTtE5Hpv/SoR+XzMe1wvIi/HvFYR+bKIbAY2e+v+03uPFhFZ\nIyILYvb3i8j/FpGtItLqbZ8mIveKyI9iv4SI/EFE/tdY/AGZ8WGhy4yls4Bs4LeH2P6vwAeAecDJ\nwBnAt7xtXwfqgApcC9n/BlRV/wF4H/i4quar6vfHrnxjTIr4R+BX3uNCEan01v8QOA34IFAK/AsQ\nEZHpwLPA/4c7B80D1g7j864AzgTmeq9f996jFFgG/EZEsr1tXwM+A1wMFAKfBQ4ADwOfEREfuB+i\nwEeBx4bzxc3EYqHLjKUyYJ+qhg6x/VrgDlXdq6oNwHeAf/C29QBTgBle69hLajcKNcYMk9d/dAbw\nhKquAbYCi7ww81ngJlXdqaphVf2rqnbhzk1/UtXHvPPPflUdTui6U1WDqtoBoKqPeu8RUtUfAVnA\nMd6+nwe+paqb1HnT2/c1oBkXtACuAVap6p4R/pGYBLLQZcbSfqD8MP0aqoD3Yl6/560D+AGwBVgh\nIrUicsvYlWmMSWHXAStUdZ/3epm3rhzXEr91kGOmHWJ9vHbEvhCRr4vI294lzCagyPv8oT7rYWCx\nt7wY+OUIajITgIUuM5ZeATpxTe2Dqcf9Ao2a7q1DVVtV9euqOgv4OPA1EYn+4rMWL2PMkLz+WVcD\nHxaR3SKyG/gqrjvDFNz5afYgh+44xHqAdiA35vXkQfbpPUd5/be+6dVRoqrFuBYsieOzHgUuF5GT\ngeOA3x1iP5MkLHSZMaOqzcDtwL0icoWI5IpIQEQWisj3cX0TviUiFV5/hdtxJxlE5FIROUpEBGgB\nwt4DYA8wa9y/kDEm2VyBO2/MxfWpmocLLy/h+nktBe4WkSqvQ/tZ3mCeXwEfE5GrRSRDRMpEZJ73\nnmuBT3jns6OAzw1RQwEQAhqADBG5Hdd3K+rnwHdFZI44J4lIGYCq1uH6g/0SeCp6udIkLwtdZkyp\n6t24jqLfwp10dgBfwf1i+3+B1cA64C3g7946gDnAn4A2XIvZfaq6ytt2Jy6sNYnIzePzTYwxSeg6\n4P9X1fdVdXf0AfwE12/rFty553UgCPw74FPV93Ed27/urV+Lax0D+A+gG/fj72FcQDuc53Cd8t/F\ndaHopP/lx7uBJ4AVuB+YvwByYrY/DJyIXVpMCWJ9k40xxpiJSUQ+hLsCMFNVI4mux4yMtXQZY4wx\nE5CIBICbgJ9b4EoNFrqMMcaYCUZEjgOacB3+70lwOWaU2OVFY4wxxphxYC1dxhhjjDHjYMLdjLO8\nvFxnzpyZ6DKMMeNozZo1+1S1ItF1jAY7hxmTXoZz/ppwoWvmzJmsXr060WUYY8aRiLw39F7Jwc5h\nxqSX4Zy/7PKiMcYYY8w4sNBljDHGGDMOLHQZY4wxxoyDCdeny5h01NPTQ11dHZ2dnYkuZUxlZ2dT\nXV1NIBBIdCnGGDPuLHQZMwHU1dVRUFDAzJkzcff4Tj2qyv79+6mrq6OmpibR5RhjzLizy4vGTACd\nnZ2UlZWlbOACEBHKyspSvjXPGGMOxUKXMRNEKgeuqHT4jsYYcyjJfXnx74+ALwPmLUp0JcYYY4wZ\nA6pKW1eIpgM9NHf00HSgh6aO7t7XqkpuZgb5WRnkZWWQl+XvXc7PyiA3009eVgZZGb6E//BL7tC1\n7gkId1voMmaEmpqaWLZsGTfccMOwj73nnntYsmQJubm5Y1CZMaklElEU8PsmZqtvTzjClr1tbKxv\nIdjeTcAvZPh97tnnI8MvBPw+An5vuXdd3/ZMv48Mv48Mn/TbL5AhdIciXmjqoelAd1+I8oJUc8y2\npo6e3tfhyMjvE53hk94glpfljwlq/pj17vnoygLOn1s5Cn+iA2qIZycRuQj4T8AP/FxV7xqw/UvA\nl4Ew0AYsUdWNIjITeBvY5O36qqp+aXRKB0prYNOzo/Z2xqSrpqYm7rvvviMOXYsXL7bQZdJSVyhM\nY3sP+9u7ep+D7d00tnezv72bxgPd7G9zz8H2bhoP9OD3CUdV5HN0ZT5HTy7gmMoCjq4sYGpxDr5x\nDGMHukO8vauVjfXNbKhvYUN9C5v2tNIdioxbDbEKsjIoyg1QnBugOCeTKcU5FOf0vS7KDXivM711\nAQpzAvhEaO8K0d4dor0rTFtXyL3uCtHWFeJA98B14Zj9QzS0drnt3uuesHLJSVMSE7pExA/cC5wP\n1AGvi8jTqroxZrdlqvpTb//LgLuBi7xtW1V13uiW7SmdBe0N0NUKWQVj8hHGpINbbrmFrVu3Mm/e\nPM4//3wmTZrEE088QVdXF1deeSXf+c53aG9v5+qrr6auro5wOMxtt93Gnj17qK+v57zzzqO8vJyV\nK1cm+qsYc0RC4QitnSFaO0O0dPa4R0eIlo6eg8LT/vZugl7IausKDfp+IlCSm0lJboCyvCxqyvM4\nbUYppXkBukMR3t3Txt+2Bfnd2vreY3Iz/cypLOCYynyO9oLYMZMLmFSQNeLLYsH2bjbEhKsN9c1s\n29eOeg1IxbkBjq8q5PoPzuT4qkKOryqksjCbUFjpiUToCSuhsPccibj14Zj1kf7b+7ZFX7v9M/0+\nSvL6h6giLzwF/EfezTwzI5OSvMwR/RlFdYcihCJjEzzjaek6A9iiqrUAIvI4cDnQG7pUtSVm/zxg\n5O2A8Sid5Z6D22DKSePykcaMte/8YQMb61uG3nEY5lYV8u2PH3/I7XfddRfr169n7dq1rFixgief\nfJLXXnsNVeWyyy7jxRdfpKGhgaqqKp555hkAmpubKSoq4u6772blypWUl5ePas3GxFJVIgrhiBLR\n6MO9VlXCEaXbC04tHT0x4anvdav3urWzp98+rZ2uNeRwsjJ8lOVlUpqfSUluJjVluZTkZVKWl9n3\nnJtJWX4mpXlZFOUE4rqE2NzRw5a9rWza3ca7e1p5d08rf35nL0+sruvdpygnwDGVBcypzOeYyQW9\ngax0kJChqtQ1drChvoWN9c1s3OVC1q7mvlHDU4tzmFtVyGUnV3F8VRFzqwqpKspOeH+niSIzw0fm\nGI0zjCd0TQV2xLyuA84cuJOIfBn4GpAJfCRmU42IvAG0AN9S1ZcGOXYJsARg+vTpcRdPiTfXT7DW\nQpcxo2TFihWsWLGCU045BYC2tjY2b97MggULuPnmm/nmN7/JpZdeyoIFCxJcqUkmqsqWvW28uHkf\nL29u4N09bYQjSlj7QlNEXZ+ncDRURSCi0X1G9vkBv1CY7VpUCrIzKMjOoLIwm4LsDAqzAxRkByjM\nyaAgOxCzLoOinABl+ZnkBPxjEkqKcgKcNqOU02aU9lu/v62Ld/e4ILZpTyub97Tyhzfr+dXf+lrW\nyvOzOGayaxXzi7igtauF5o4eAHwCsyryOaOm1Gu9KmLulMJRaxEywxdP6Brsb9lBf/1V9V7gXhFZ\nBHwLuA7YBUxX1f0ichrwOxE5fkDLGKr6APAAwPz58+P/X6s0JnQZkyIO1yI1HlSVW2+9lS9+8YsH\nbVuzZg3Lly/n1ltv5YILLuD2229PQIUmWexr6+J/tuzjpc37eGlzA3taugCoKc/j9JklZGb48PsE\nEcEv4i2DXwSfT/CJ4BPX6dwtC36fm3rE73PHSMz2zAxfv8AUDVKF2YEJMXJtOMryszgrP4uzZpf1\nrlNV9rR09baIbdrdyrt72/j16zsIR5RjJxdw8YlTei8PHju5kJxMfwK/hRkontBVB0yLeV0N1B9i\nX4DHgfsBVLUL6PKW14jIVuBoYPURVTtQVgHkTbLQZcwIFRQU0NraCsCFF17IbbfdxrXXXkt+fj47\nd+4kEAgQCoUoLS1l8eLF5Ofn89BDD/U71i4vms6eMKu3N/LS5gZe2ryPjbvc7+vi3ABnzy5nwZxy\nzplTTnWJDbo4EiLC5KJsJhdl86GjK3rXT/QRkaZPPKHrdWCOiNQAO4FrgH5zNIjIHFXd7L28BNjs\nra8AgqoaFpFZwBxgdBNS6Sxo3D6qb2lMuikrK+Pss8/mhBNOYOHChSxatIizzjoLgPz8fB599FG2\nbNnCN77xDXw+H4FAgPvvvx+AJUuWsHDhQqZMmWId6ROssyfM399vpDgnk8rCLEpyM8d0NJyq8vau\nVl7e4kLWa9uCdIUiBPzCqdNL+MaFx3DOUeWcMLXIAsEYGs8Rj2ZkhgxdqhoSka8Az+GmjFiqqhtE\n5A5gtao+DXxFRD4G9ACNuEuLAB8C7hCREG46iS+panBUv0FpDWx7cVTf0ph0tGzZsn6vb7rppn6v\nZ8+ezYUXXnjQcTfeeCM33njjmNZmhrazqYPPP7yat3f19d4I+IVJBdlUFGRRWZhFZWE2kwqymFSY\nTWVhNpWFWUwqyKYkNxD3pbc9LZ287F0ufHnLfva1uUuGcybls+jM6XxoTgVn1JSSl5Xc00AaMxbi\n+r9CVZcDywesuz1m+aaDDnLrnwKeGkmBQyqdBW8+Bj0dEMgZ048yxpiJaM17jXzxl2vo6gnzo0+d\nTE6mnz0tnexp6WJvayd7W7qobWjnla37aek8eIqDTL+vN5hNKvDCmBfMJhVkEY4oL2/Zx8ub97Fp\nj7sMXZaXyTlzyjnnKHfJcEqRnX+NGUry/xSJThvRuB0mHZfQUowxZrz97o2d/MtT65hcmM3jS87k\nqEmHn7OwsyfM3pYu9nhhbE9LZ+/y3tZOtjS08T9b99E6IJxlZvg4Y2YpV546lQVzyjlucqFd1jKJ\n0dkCDe/A3rfdA4XiGVAyo+95gs7dmQKhKzqCcZuFLmNM2ohElB89v4l7V27lzJpSfrr4tLimAsgO\n+Jlelsv0ssN3Zu/oDrO31bWWhSIRTp1eQnbARsKZcdR9APZtgr3vwN6NLmA1vAPNMbNYBXJB/NDd\n2v/YnNL+Iaz3eSYUT4OMrHH9KlHJH7pKbNoIY0x6ae8K8bUn1vLchj185oxpfOeyE8jMGN3JHHMy\n/cwoy2NGWd6ovq+ZoLrboW2ve7TvhbY9EAlDdjHkFHvPJX3LGaM411eoG/Zv7mu52vs2NLztGlOi\nM1T5M6H8GJh+Fkz6J5g01zW0FE130/93NLorXk3vQeN7fc971sOm5e4+zb0ECqYcIpTNgMIq8I3N\nD4zkD125pe4vgIUuY0waqPc6zL+zu4XbLp3LZ8+emVTzT5lx1NPpBajoY4+7dV7bngEBay90tw3v\nvQO5AwJZzHNOyaG3dbbEtFp5AWv/Foh4l7PFD2VHweQT4aRPu2BVcZzrSuQ/TGTJLXWPqacevC0S\ngbbdLpTFBrKm92D7y7Du1/SbftSXASdeDVfeP7w/kzgkf+gC9x/DQpcxJsX9/f1GljziOsz/4vrT\nOe+YSYkuycQrEobOZuhscpfNIj1uXSQE4R73HAl760N9r8Oxrwc8wjHLXa0DAtZe6GoevJbsYsiv\nhPxJUHWKW86r6FuXP8nNgekPQEeTq7n3ubHvdey2pvehY533/eIMcCUzXYvVsZe4YDXpOCifM/qX\n/nw+13pVWAUzPnjw9lC3u2QZG8ai/cVHWeqErp2jM9+qMemoqamJZcuWccMNNwzruIsvvphly5ZR\nXFw8RpWZqN+v3ck3nnQd5h/7wpnMqZyYHYVTWiTigsxBQWRAGDloWxN0tTBmtyUWP2Tm9YWlyuNh\n9kcg3wtSeZNiwlTF8EJN3hFMehzuGfzPobPJtZBNOg4qjnE1TwQZmVA22z3G+qPG/BPGQ2kNbPgv\nl1ZH8zqzMWmiqamJ++6776DQFQ6H8fsP3bdh+fLlh9xmRsfADvP3Lz5t0BsdmxGIRFwrUdMO1+LR\nvKNvuXV3TGho5rDByZ/Z/3JafqXrhxTbFyqn2IUNX8BdxvJnuGdfhrfO7633tkdf+2Je927LcIHL\nNzY3Zz5i/oAX+CqG3jfNpEjomgUacf+DjENSNSbV3HLLLWzdupV58+YRCATIz89nypQprF27lo0b\nN3LFFVewY8cOOjs7uemmm1iyZAkAM2fOZPXq1bS1tbFw4ULOOecc/vrXvzJ16lR+//vfk5NjczeN\nxIHuEF/9teswf83p07jj8tHvMJ8WQt3QstMLVHVeoHo/JmTthHBX/2Oyitwot4LJ7pJXPP2VArmu\nU7cxh5A6oQtcvy4LXSbZPXsL7H5rdN9z8omw8K5Dbr7rrrtYv349a9euZdWqVVxyySWsX7+emho3\nOnjp0qWUlpbS0dHB6aefzlVXXUVZWVm/99i8eTOPPfYYDz74IFdffTVPPfUUixcvHt3vkUasw/ww\nhLpdP5zgtoNbqpp2QOsuDmqhyq+Eomkw5WQ49lIong5F1W5d8TTILkrIVzGpLcVC17bE1mFMijjj\njDN6AxfAj3/8Y377298CsGPHDjZv3nxQ6KqpqWHevHkAnHbaaWzfvn3c6j0cEbkI+E/cbcx+rqp3\nDdg+A1gKVABBYLGq1nnbvo+7n6wPeB64SVXHqGNOnzfeb+QLj6yh0zrM94mEXWft4FbYX+tGvAW3\nwv6tbr2G+/b1ZUDhVBekZp3rQlQ0TBVNc9sC2Yn6JiaNpUboyquAQJ6NYDSp4TAtUuMlL6+vg+uq\nVav405/+xCuvvEJubi7nnnsunZ2dBx2TldXXOdfv99PR0TEutR6OiPiBe4HzgTrgdRF5WlU3xuz2\nQ+ARVX1YRD4C3An8g4h8EDgbOMnb72Xgw8Cqsaw5rTvMRyLQWu+CVDRQRZeD29zIvqjMfPeDu2oe\nnHCVm2agtMaFqoLJYzbPkjEjkRqhS8SmjTBmBAoKCmhtbR10W3NzMyUlJeTm5vLOO+/w6quvjnN1\nI3IGsEVVawFE5HHgciA2dM0FvuotrwR+5y0rkA1kAgIEgD1jVWhadZjv6YD6N7xQtaWv9SpYC6GY\nsJ6R7c7t5UfDMRe77iOl3iiz/ErrP2WSTmqELnC/cPa+negqjElKZWVlnH322Zxwwgnk5ORQWVnZ\nu+2iiy7ipz/9KSeddBLHHHMMH/jABxJY6bBNBWLuGUIdcOaAfd4ErsJdgrwSKBCRMlV9RURWArtw\noesnqjroSUZElgBLAKZPnz7sItOiw7wqvP8qvPkYbPhd3xxSvoCbr6lsNsw+z4Wsstmu5aqgauKN\nzDNmBFIodM2Cd//orvtbs7Ixw7Zs2bJB12dlZfHss88Oui3ab6u8vJz169f3rr/55ptHvb4jNFhT\nyMA+WTcDPxGR64EXgZ1ASESOAo4Dqr39nheRD6nqiwe9oeoDwAMA8+fPH1afr5TvMB/c5mb8fvMx\nNyN4IA/mXgZzL4eKY93lwMPNNG5MCkmdv+mlNe7eSi07XedJY4xxLVvTYl5XA/WxO6hqPfAJABHJ\nB65S1Wav9epVVW3ztj0LfAAXzEZFynaY72iCjb+DNx+H918BBGo+BOfe6kYKZuUnukJjEiKFQlfM\ntBEWuowxzuvAHBGpwbVgXQMsit1BRMqBoKpGgFtxIxkB3ge+ICJ34lrMPgzcM1qF/XH9Lv758bVU\nFmax7AtncnSyd5gPh2Drn12L1jvPuHmvyo+Gj34bTrraTcdgTJpLzdA169xEVmLMEVHV1LqsNIhx\nmG1h4OeFROQrwHO4KSOWquoGEbkDWK2qTwPnAneKiOJasb7sHf4k8BHgLdwlyT+q6h9Gq7aq4hzO\nmlXGf3x6XnJ3mN/9lmvRWveEm9U9pxROuw5OvgaqTrXO7sbESJ3QVVAF/iybq8skpezsbPbv309Z\nWVnKBi9VZf/+/WRnj+/8SKq6HFg+YN3tMctP4gLWwOPCwBfHqq6Tqot5+LNnjNXbj63WPfDWb1yr\n1p71rjP80RfCvEVw1Pl2OzZjDiF1QpfP50bA2LQRJglVV1dTV1dHQ0NDoksZU9nZ2VRX22WmpNTT\n4S4bvvk4bH3B3Xpt6ny4+Idunqzc0kRXaMyElzqhC7y5uqylyySfQCDQbwZ4YyaM4DZ4+W5vmocW\nKKyGc74KJ10DFUcnujpjkkrqha5tf3HzwaToJRpjjBk3W1fCb653I8PnXuH6ac1cYHNnGXOEUix0\n1UDPAWjb424DYYwxZvhU4dX7YcW/Qvkx8JnH3PnVGDMicf1cEZGLRGSTiGwRkVsG2f4lEXlLRNaK\nyMsiMjdm263ecZtE5MLRLP4g0ZOC9esyxpgjE+qC338ZnrvV3Xrn889b4DJmlAwZumJuGLsQd4+y\nz8SGKs8yVT1RVecB3wfu9o6di5sX53jgIuA+7/3GRuy0EcYYY4andTc8dAms/RV8+Jtw9S8hK8nn\nDzNmAonn8uKQN4xV1ZaY/fPou83G5cDjqtoFbBORLd77vTIKtR+saDr4Mix0GWPMcO1cA49fC53N\ncPUj7jY9xphRFU/oiueGsYjIl4GvAZm4CQWjx7464Nipgxw7opvF9vJnuNnobQSjMcbE781fw9M3\nQkElfO55mHxCoisyJiXF06crnhvGoqr3qups4JvAt4Z57AOqOl9V51dUVMRR0mGU1FhLlzHGxCMS\nhhXfgt8ugWlnwBdWWeAyZgzF09I15A1jB3gcuP8Ijx250llQt9qmjTDGmMPpaIQnP+cmOj39C3DR\nneAPJLoqY1JaPC1dvTeMFZFMXMf4p2N3EJE5MS8vATZ7y08D14hIlnfD2TnAayMv+zBKZ0FXMxwI\njunHGGNM0mp4Fx78KGx7ET7+n3DJDy1wGTMOhmzpivOGsV8RkY8BPUAjcJ137AYReQLX6T4EfNm7\nn9nYiY5gbNwGeWVj+lHGGJN03n0Onvo8+DPhuj/AjLMSXZExaSOuyVHjuGHsTYc59nvA9460wGGL\nnaurev64fawxxkxoqvDyf8ALd8DkE+GaZVA8bejjjDGjJrVmpAcongGIdaY3xpio7gNudOL6J+H4\nT8Dl90JmbqKrMibtpF7oCmRDUbWFLmOMAWiug8cXwa518NHb4Zyv2SAjYxIk9UIXuEuMNleXMSbd\nvf8q/Hox9HTCZx6HYy5KdEXGpLXUvFW8zdVljEl3ax6Ghy51t/H5wgsWuIyZAFK0pWsWHNjnbmeR\nXZToaowxZvyEe+CPt8LrD8Lsj8Anl0JOSaKrMsaQqi1dvTe+tkuMxpg00tEEv7zSBa6zvgKLfmOB\ny5gJJMVDl11iNMakkb8/DNtfgit+Chd+z92P1hgzYaRo6PLm6mq0li5jTBrZ9y7kV8K8zyS6EmPM\nIFIzdGXmuROPtXQZY9JJcLsbSGSMmZBSM3SBu8RofbqMMekkWNvXvcIYM+GkeOiyli5jTJro6YDW\n+r7uFcaYCSeFQ1cNtO5yt78wxphU17jdPVtLlzETVuqGrmi/huiJyBhjUlm0Zd9auoyZsFI3dNm0\nEcaYdBLtw2od6Y2ZsFI4dHknHgtdxph0EKyF7GLILU10JcaYQ0jd0JVTAjmlNleXMSY92MhFYya8\n1A1d4Fq7rKXLGJMOGrdZfy5jJrgUD102bYQxJg2EuqHpfWvpMmaCS/3Q1VznTkjGGJOqmneARix0\nGTPBpX7o0oj7BWiMManKRi4akxRSO3SV2AhGY9KdiFwkIptEZIuI3DLI9hki8oKIrBORVSJSHbNt\nuoisEJG3RWSjiMwcz9rj1jtHl7V0GTORxRW64jhpfc07Ia3zTl4zYraFRWSt93h6NIsfks3VZUxa\nExE/cC+wEJgLfEZE5g7Y7YfAI6p6EnAHcGfMtkeAH6jqccAZwN6xr/oIBGshkAf5kxJdiTHmMIYM\nXXGetN4A5nsnrSeB78ds61DVed7jslGqOz555ZBZYKHLmPR1BrBFVWtVtRt4HLh8wD5zgRe85ZXR\n7d55LkNVnwdQ1TZVnZj3FYuOXBRJdCXGmMOIp6VryJOWqq6MORm9ClQzEYi4E5HN1WVMupoK7Ih5\nXeeti/UmcJW3fCVQICJlwNFAk4j8l4i8ISI/8H6EHkRElojIahFZ3dDQMMpfIQ7BWpsuwpgkEE/o\niuekFetzwLMxr7O9k9GrInLFYAeM6QnL5uoyJp0N1vSjA17fDHxYRN4APgzsBEJABrDA2346MAu4\nfrAPUdUHVHW+qs6vqKgYpdLjFAm7e8xafy5jJrx4Qlc8Jy23o8hiYD7wg5jV01V1PrAIuEdEZh/0\nZmN5wiqdBY3vQTg0uu9rjEkGdcC0mNfVQH3sDqpar6qfUNVTgH/11jV7x77htfKHgN8Bp45P2cPQ\nUg/hbhu5aEwSiCd0DXnSAhCRj+FOWJepald0varWe8+1wCrglBHUO3ylsyDSAy114/qxxpgJ4XVg\njojUiEgmcA3Qb0CPiJSLSPRceCuwNObYEhGJ/hL8CLBxHGoeHhu5aEzSiCd0xXPSOgX4GS5w7Y1Z\nXyIiWd5yOXA2433S6h3BaP26jEk3XgvVV4DngLeBJ1R1g4jcISLRgT3nAptE5F2gEvied2wYd2nx\nBRF5C9fq/+A4f4WhRfusWugyZsLLGGoHVQ2JSPSk5QeWRk9awGpVfRp3OTEf+I240TPveyMVjwN+\nJiIRXMC7S1XHN3TFztU1+7yys2XQAAAgAElEQVRx/WhjTOKp6nJg+YB1t8csP4kbdT3Ysc8DJ41p\ngSMVrAV/JhRWJboSY8wQhgxdENdJ62OHOO6vwIkjKXDECqZARrZ1pjfGpKZgLZTMBN+gAyuNMRNI\nas9ID+DzudYuu7xojElFwe3Wid6YJJH6oQu8EYwWuowxKUbVm6PL+nMZkwzSJHR5LV2RSKIrMcaY\n0dO2F3raLXQZkyTSJ3SFOqBtd6IrMcaY0dM7ctEuLxqTDNIkdNmNr40xKcjm6DImqaRZ6LJ+XcaY\nFBKsBfFD0bSh9zXGJFx6hK7CavBlWEuXMSa1BLdBUTVkZCa6EmNMHNIjdPkzoHiGhS5jTGqxkYvG\nJJX0CF3gTkwWuowxqcRClzFJJb1CV+N2N6+NMcYkuwNB6GyykYvGJJE0Cl010NUCB/YnuhJjjBk5\nu9G1MUknjUKXTRthjEkhQQtdxiQbC13GGJOMoqGrZGZCyzDGxC99QlfxdBCfzdVljEkNwVooqIJA\nTqIrMcbEKX1CV0aWm6/LWrqMManARi4ak3TSJ3SBd+NrC13GmBTQuA1KZya6CmPMMKRZ6LK5uowx\nKaCrDdr2WEuXMUkm/UJXRxA6mhJdiTHGHLnG7e7ZQpcxSSXNQpc3iWCjdaY3xiSxaIt9iU2Makwy\nSbPQZdNGGGNSQPQcZrPRG5NU0it0ReezsdBljElmjdsgtwyyixJdiTFmGOIKXSJykYhsEpEtInLL\nINu/JiIbRWSdiLwgIjNitl0nIpu9x3WjWfywZeZBwRSbq8sYk9xsughjktKQoUtE/MC9wEJgLvAZ\nEZk7YLc3gPmqehLwJPB979hS4NvAmcAZwLdFpGT0yj8CJTUWuowxyS24zUKXMUkonpauM4Atqlqr\nqt3A48DlsTuo6kpVPeC9fBWo9pYvBJ5X1aCqNgLPAxeNTulHyKaNMMYks1AXNNdZJ3pjklA8oWsq\nsCPmdZ237lA+Bzx7hMeOvdIaaNsN3e0JLcMYY45I43uAWkuXMUkontAlg6zTQXcUWQzMB34wnGNF\nZImIrBaR1Q0NDXGUNAK9IxjtEqMxJgn1jly00GVMsokndNUB02JeVwP1A3cSkY8B/wpcpqpdwzlW\nVR9Q1fmqOr+ioiLe2o+MzdVljElm0XOXTRdhTNKJJ3S9DswRkRoRyQSuAZ6O3UFETgF+hgtce2M2\nPQdcICIlXgf6C7x1iRPtB2H9uowxyShYC1mFbsoIY0xSyRhqB1UNichXcGHJDyxV1Q0icgewWlWf\nxl1OzAd+IyIA76vqZaoaFJHv4oIbwB2qGhyTbxKvnGJ3srLQZYxJRsFa18olg/XeMMZMZEOGLgBV\nXQ4sH7Du9pjljx3m2KXA0iMtcEzYCEZjTLIKboPJJya6CmPMEUivGemjSmoguD3RVRhjzPCEQ9D0\nnnWiNyZJpWfoKp0FzTvcfDfGGJMsmndAJGShy5gklb6hC/XmuzHGpLI4bmM2w7t92ToRWSUi1QO2\nF4rIThH5yfhVfQg2ctGYpJbGoQvr12VMiovzNmY/BB7xbmN2B3DngO3fBf4y1rXGxeboMiappWno\nsrm6jEkTQ97GDBfGXvCWV8ZuF5HTgEpgxTjUOrTgNsjIgfzJia7EGHME0jN05Za5eW6spcuYVBfP\nrcjeBK7ylq8ECkSkTER8wI+Ab4x5lfEKboOSmeBLz1O3MckuPf/PFXGtXRa6jEl18dyK7GbgwyLy\nBvBhYCcQAm4AlqvqDoYwbrcyC9bapUVjklhc83SlpNJZsOvNRFdhjBlbQ96KTFXrgU8AiEg+cJWq\nNovIWcACEbkBN/lzpoi0qepBnfFV9QHgAYD58+cPem/aEYtEoHE7HPXRMXl7Y8zYS8+WLnBzdTW9\n7+a9McakqnhuY1buXUoEuBVvMmdVvVZVp6vqTFxr2CODBa5x07YbQh02ctGYJJa+oat0lpvvpnnI\nKwfGmCSlqiEgehuzt4EnorcxE5HLvN3OBTaJyLu4TvPfS0ixQ7GRi8YkvfS+vAh99zEzxqSkOG5j\n9iTw5BDv8RDw0BiUF7+gN9q6xM5XxiSr9G7pAutMb4xJDsFa8GVA0bSh9zXGTEjpG7oKJrv5bhq3\nJ7oSY4wZWrAWimeAP30vUBiT7NI3dNm0EcaYZNK4zbpCGJPk0jd0gbvEaKHLGDPRqbo+XdaJ3pik\nluahq8adyCKRRFdijDGHdmA/dLVY6DImyaV36CqpgXAXtO5KdCXGGHNoNnLRmJSQ3qHLRjAaY5KB\nzdFlTEqw0AUWuowxE1uwFhAomZHoSowxI5DeoauoGnwBC13GmImtcZs7X2VkJboSY8wIpHfo8vnd\nL8fGbYmuxBhjDs3unGFMSkjv0AU2bYQxZuKz6SKMSQlxhS4RuUhENonIFhG5ZZDtHxKRv4tISEQ+\nOWBbWETWeo+nR6vwUVM6y53QVBNdiTHGHKyzGQ7ss5GLxqSAIe8nISJ+4F7gfKAOeF1EnlbVjTG7\nvQ9cD9w8yFt0qOq8Uah1bJTOgu42aG+A/EmJrsYYY/qLThdhLV3GJL14WrrOALaoaq2qdgOPA5fH\n7qCq21V1HZB8s4z2jmC0fl3GmAmo0UKXMakintA1FdgR87rOWxevbBFZLSKvisgVg+0gIku8fVY3\nNDQM461HQbTJ3vp1GWMmoui5qWRmQsswxoxcPKFLBlk3nA5Q01V1PrAIuEdEZh/0ZqoPqOp8VZ1f\nUVExjLceBcXTQXwWuowxE1OwFvIrISs/0ZUYY0YontBVB0yLeV0N1Mf7Aapa7z3XAquAU4ZR39jL\nyISiaRa6jDETU3C7daI3JkXEE7peB+aISI2IZALXAHGNQhSREhHJ8pbLgbOBjYc/KgFKZ9lcXcaY\niSlYa/25jEkRQ4YuVQ0BXwGeA94GnlDVDSJyh4hcBiAip4tIHfAp4GcissE7/DhgtYi8CawE7how\n6nFiKK2xli5jzMTT0wGt9Ra6jEkRQ04ZAaCqy4HlA9bdHrP8Ou6y48Dj/gqcOMIax17pLOhohANB\nyC1NdDXGGOM0bnfPNhu9MSnBZqSHvl+RdonRGDORRFvgLXQZkxIsdIHN1WWMmZh6Q5ddXjQmFVjo\ngr75byx0GWMmkuA2yC6GnJJEV2KMGQUWugACOVBQZZ3pjTETi41cNCalWOiKKp1locsYM7FY6DIm\npVjoiiqtsY70xpiJI9QNzTusE70xKcRCV1RpDbTtga62RFdijDEucGnEWrqMSSEWuqJs2ghjzEQS\nHdhjocuYlGGhK6p32gjr12WMmQCi5yK776IxKcNCV1T0xGahyxgzEQRrIZAH+ZMSXYkxZpRY6IrK\nLoTccpuryxgzMTRucy3wIomuxBgzSix0xbJpI4wxE0WwFkpnJroKY8wostAVq3SWtXQZYxIvEnY3\nu7ZO9MakFAtdsUpnQctO6OlMdCXGmHTWUg/hbgtdxqQYC12xSmsAhab3El2JMWaUiMhFIrJJRLaI\nyC2DbJ8hIi+IyDoRWSUi1d76eSLyiohs8LZ9etyKtpGLxqQkC12xbNoIY1KKiPiBe4GFwFzgMyIy\nd8BuPwQeUdWTgDuAO731B4B/VNXjgYuAe0SkeFwKj56DrKXLmJRioSuWhS5jUs0ZwBZVrVXVbuBx\n4PIB+8wFXvCWV0a3q+q7qrrZW64H9gIV41J14zbwZ0Jh1bh8nDFmfFjoipVTAtlFsH9roisxxoyO\nqcCOmNd13rpYbwJXectXAgUiUha7g4icAWQCg54cRGSJiKwWkdUNDQ0jrzpYCyUzwecf+XsZYyYM\nC12xRKDqFFj7K1j3m0RXY4wZucEmudIBr28GPiwibwAfBnYCod43EJkC/BL4J1WNDPYhqvqAqs5X\n1fkVFaPQGBbcZpcWjUlBFroGuuoXMPU0+K/Pw5/+jxu6bYxJVnXAtJjX1UB97A6qWq+qn1DVU4B/\n9dY1A4hIIfAM8C1VfXVcKlZ1ocs60RuTcix0DZRXDv/wOzjtn+Dl/4DHF0FnS6KrMsYcmdeBOSJS\nIyKZwDXA07E7iEi5iETPhbcCS731mcBvcZ3sx6/pu20v9LRbS5cxKSiu0BXHkOsPicjfRSQkIp8c\nsO06EdnsPa4brcLHVEYmfPweuORHsPl5+PnHrJ+XMUlIVUPAV4DngLeBJ1R1g4jcISKXebudC2wS\nkXeBSuB73vqrgQ8B14vIWu8xb8yLtpGLxqSsjKF2iBlyfT6uqf51EXlaVTfG7PY+cD2ub0TssaXA\nt4H5uH4Ua7xjG0en/DF2+ueh/Gh44h/hwY/Apx6C2ecluipjzDCo6nJg+YB1t8csPwk8OchxjwKP\njnmBAzV6d8UotcuLxqSaeFq6hhxyrarbVXUdMLCT6YXA86oa9ILW87j5bpJHzYfgCyvd0O1Hr4JX\nf+r6XBhjzFgI1oL4oWja0PsaY5JKPKErniHXIzp21Idbj7bSGvjcCjj6QvjjN+HpGyHUleiqjDGp\nKFgLxdNcNwdjTEqJJ3TFM+R6RMeO+nDrsZBVAJ/+FSy4Gd74JTx8GbRNwIBojEluNnLRmJQVT+ga\ncsj1GB078fh88NHb4JNLYdeb8MC5sGtdoqsyxqSSYK11ojcmRcUTuoYccn0YzwEXiEiJiJQAF3jr\nktsJV8FnnwUUll4IG36b6IqMMangQBA6myx0GZOihgxd8Qy5FpHTRaQO+BTwMxHZ4B0bBL6LC26v\nA3d465Jf1Smug33lCfCb62Hlv0Fk0MmqjTEmPjZy0ZiUNuSUERDXkOvXcZcOBzt2Kd5kgymnoBKu\n/2/476/CX/4d9myAK38GWfmJrswYk4yC0dBlLV3GpCKbkX6kMrLg8nvhwjth03L4xQXQ+F6iqzLG\nJKNo6CqZmdAyjDFjw0LXaBCBs26Aa5+Eljp48DzY/nKiqzLGJJtgLRRUQSAn0ZUYY8aAha7RdNRH\n4fN/hpxSeORyWJ2aV1WNMWPERi4ak9IsdI228qPgCy/ArPNcX69nvg7hnkRXZYxJBo3brBO9MSnM\nQtdYyC6CRb+GD/4zvP5z+OWV0Lon0VUZYyayrjZo22Ohy5gUFtfoRXMEfH644LtQeTw8/c9w97Ew\n/Sw49hI45mI7sRpj+mu0kYvGpDoLXWPt5Gug6lR46wl4Zzk897/dY9LxcOzFLoRNmec64xtj0lfv\nyEX7QWZMqrLQNR4qjoaPfMs9gtvc1BLvPAMv/Qhe/AEUTnWtX8deDDPOsRvdGpOOgrXu2VrBjUlZ\nFrrGW2kNnPVl92jfD5ufcwHsjUfh9QchqwjmnO8C2FHnQ3Zhois2xoyHYC3klrs+ocYkkZ6eHurq\n6ujs7Ex0KWMqOzub6upqAoHAEb+Hha5EyiuDeYvco/sA1K6CTc/Apj/C+ifBF4CaD7kAdszFUFiV\n6IqNMWPFRi6aJFVXV0dBQQEzZ85EUrSrjKqyf/9+6urqqKk58v9PLXRNFJm5Xh+viyEShh2vuQD2\nzjNu2olnvu76hh17iXtUHGv9wIxJJcFtMOODia7CmGHr7OxM6cAFICKUlZXR0NAwovex0DUR+fww\n4yz3OP+70LCpL4D9+bvuUVID0z8ApbPdr+Oy2W7Uk12aMCb5hLqguc5GLpqklcqBK2o0vqOFrolO\nBCYd6x4Lvg4tu+DdZ2HTs1D7F3jzsf7755a7E3c0hEUfZbMtkBkzUTW+B6iNXDQmxSV16Lp/1VZy\nM/3841kz0iJlA1A4BeZ/1j3A9QVr3OY64e7f6p6DtYcIZGVey9ggoSynePy/izHG6R25aC1dxgxX\nU1MTy5Yt44Ybbhj2sffccw9LliwhNzd3DCo7WNKGrkhEWfNeI396ew+vbQ9y1ydOpCD7yEcUJK3M\nXDcBa+XxB287VCDb/hKse7z/vrll7oRfVA35k6Ggsv9zfiXkllo/MmPGgk2MaswRa2pq4r777jvi\n0LV48WILXUPx+YQH/uE0fvZiLT9csYmN9S3cu+hU5lbZFAu9hgxk2yG4tX8o27UO2p6H7raDj/EF\nXPgaGMgGPudVgD9p/2oZM/6CtZBV6H7YGJPEvvOHDWysbxnV95xbVci3Pz7Iv2OeW265ha1btzJv\n3jzOP/98Jk2axBNPPEFXVxdXXnkl3/nOd2hvb+fqq6+mrq6OcDjMbbfdxp49e6ivr+e8886jvLyc\nlStXjmrdg0nqfxl9PuH/OXc2p04v5sbH3uDK+/6HOy4/nqvnT0ufy41HKjMXKue6x2Ci94Fr3Q1t\nu929I3uf97hf5u+/Ah3Bg48Vn+tb1hvGJkPBlJjnSvecN8nCmTHgQldpjbUkG3ME7rrrLtavX8/a\ntWtZsWIFTz75JK+99hqqymWXXcaLL75IQ0MDVVVVPPPMMwA0NzdTVFTE3XffzcqVKykvLx+XWlPi\nX7wzZ5Wx/KYF3PT4G3zzqbd4bVsj373ieHIzU+LrJUZWvnuUzT78fqEuaNt7mIC2G3a/Be17QSMD\nDhbIn9Q/lA0W0vLK3YjOdBQOQWs9NL3vHi31rv9d4VT3KKqGnJKJ9491JAJo+v53G67gNphyUqKr\nMGbEDtciNR5WrFjBihUrOOWUUwBoa2tj8+bNLFiwgJtvvplvfvObXHrppSxYsCAh9aVMKinPz+KR\nz57Jj1/YzI//vJm3djZx37WnctSkgkSXltoysqB4mnscTjgE7Q1eGNsNrbv6P7fshJ1roH0foP2P\nFX//cJZfCRnZ3saYfVWHuW7A+qxC17ctr9w955a7CWxzyyAzf2yCTbjHTRXQvKMvWDXFLLfsBA0f\n/j0ycqBoakwQiwlk0ddZhSOvP9Tt/hu273X/ndr2Dlhu8P4b74UD+2HRr93dFczhhUPQ9B7MvTzR\nlRiT9FSVW2+9lS9+8YsHbVuzZg3Lly/n1ltv5YILLuD2228f9/pSJnQB+H3CV88/mvkzS/hfj6/l\nsp/8D3d+4kQunzc10aUZf4YbeVk45fD7hXvcP9q9gSwazrxWtKb3Ycff3D9UUXLQwoCAIYdeF12v\nCp3NEOk5RP1ZXiAriwlk0XBWdnBYyylx3zk6/1I0RA0MV631A1oAxd15oHi6m4eteHr/R8EUV2fL\nTve+LfUxyzvdXQ3adh/cqpiZP0ggq3LLBZPd5eR2Lzi1NfSFq9jlzubB/2wyciC/wl0uLpoGU091\ny8XTB9/f9Ne8AyIh60RvzBEqKCigtbUVgAsvvJDbbruNa6+9lvz8fHbu3EkgECAUClFaWsrixYvJ\nz8/noYce6nesXV4cgQVzKnjmnxdw42N/56bH1/K3bUFuv3Qu2QG71DHh+QMuGBQlICirQlcrHNjn\n7ot5YL9bPrDfteYcCHrb9rl5lQ7sh65DdRgV17rU1UK/1jTxuaBTPB1qFrjnoml9oapw6tA3PM/M\ndeG1ev7g28MhF7yad0JLnfccE9L2bHCXgw8nu9i1LuZNcgMx8s9zAySij/xJfctZ+Yd/L3N4NnLR\nmBEpKyvj7LPP5oQTTmDhwoUsWrSIs846C4D8/HweffRRtmzZwje+8Q18Ph+BQID7778fgCVLlrBw\n4UKmTJkyLh3pRVWH3msczZ8/X1evXj0q79UTjvDDFZv42V9qOb6qkPuuPZUZZXmj8t7GAO6S26HC\nWUeja/nqF6qqXLBMtFC3a2Vr3ukCWFah11pV4Vrqhgp+o0xE1qjqIVJkchn2Oez1n7vbfH3tbbu/\nqklKb7/9Nscdd1yiyxgXg33X4Zy/4mrpEpGLgP8E/MDPVfWuAduzgEeA04D9wKdVdbuIzATeBjZ5\nu76qql+K5zNHQ8Dv49aFx3H6jFK+/ps3ufTHL/ODT53ERScMcYnLmHhlZMZ32XSiyciEkpnuYRIr\nuM27RDs50ZUYY8aYb6gdRMQP3AssBOYCnxGRgfMMfA5oVNWjgP8A/j1m21ZVnec9xi1wxfrY3Er+\n+8ZzmFWRx5ce/Tt3/GEj3aGBI+mMMSYBgtvcdBG+IU/HxpgkF8//5WcAW1S1VlW7gceBgcNsLgce\n9pafBD4qE2yirGmlufzmSx/k+g/OZOn/bOPTD7zCzqaORJdljEl3wVq756IxaSKe0DUV2BHzus5b\nN+g+qhoCmoEyb1uNiLwhIn8RkUEnxhCRJSKyWkRWNzQ0DOsLDEdmho//c9nx3LvoVDbvaeOSH7/E\nynf2jtnnGWPMYUUiriN9qYUuY9JBPKFrsBargb3vD7XPLmC6qp4CfA1YJiIH3adHVR9Q1fmqOr+i\noiKOkkbmkpOm8Icbz2FKUQ7/9NDrfP+P7xAK2+VGY1KRiFwkIptEZIuI3DLI9hki8oKIrBORVSJS\nHbPtOhHZ7D2uG/Xi2nZDqNNClzFpIp7QVQfEznxZDdQfah8RyQCKgKCqdqnqfgBVXQNsBY4eadGj\noaY8j9/e8EGuOX0a963ayrU//xt7WzoTXZYxZhTF2Sf1h8AjqnoScAdwp3dsKfBt4ExcN4tvi0jJ\nqBYYrHXPNl2EMWkhntD1OjBHRGpEJBO4Bnh6wD5PA9FfgZ8E/qyqKiIV3kkPEZkFzAFqR6f0kcsO\n+LnrqpP40adOZl1dMxf/+CX+umVfossyxoyeePqkzgVe8JZXxmy/EHheVYOq2gg8D1w0qtVZ6DJm\nxJqamrjvvvuGfdzFF19MU1PTGFR0aENOGaGqIRH5CvAcbsqIpaq6QUTuAFar6tPAL4BfisgWIIgL\nZgAfAu4QkRAQBr6kqoPcITmxrjqtmhOri7jhV3/n2l/8jQ/UlOHzue4WEVVUvWfcc0TdrQYiqofc\nJ/o6uk9pXiazKvKYVZ7P7EnuuaY8j5xMm7DVmDE0WJ/UMwfs8yZwFW5anCuBAhEpO8Sxg87aKyJL\ngCUA06cPYyb+4DbwZUBh9dD7GmMGFQ1dN9xwQ7/14XAYv//Q/8YuX758rEs7SFzzdKnqcmD5gHW3\nxyx3Ap8a5LingKdGWOO4OLqygN9/+WzuevYdNtQ3IyL4BPfsgwzx4RNBBHzeNvc6ui66/uB9EGho\n7WL19kZ+v7b/ldmpxTleGMtjVkU+syvymVWRx+TCbHy+CTUAdNhC4QgNbV2U5Gba3QDSTFcojE+E\ngD/h0yDE0yf1ZuAnInI98CKwEwjFeaxbqfoA8AC4yVHjri5YC8Uz3C2jjEkFz94Cu98a3fecfCIs\nvOuQm2+55Ra2bt3KvHnzCAQC5OfnM2XKFNauXcvGjRu54oor2LFjB52dndx0000sWbIEgJkzZ7J6\n9Wra2tpYuHAh55xzDn/961+ZOnUqv//978nJyRnd70GK3gboSOVlZfDdK04Y08/o6A6zbV87tfva\nqG1op7ahja0N7Ty5po727r4bG+cE/NSU57lAVpHP7Io8Zle41rG8rMT/Z1NVWjpD1Dd19D52NnX2\ne727pZOIQoZPOGZyASdVF3FSdTEnTi3imMkFE+EfZDMKOnvCvLO7lfU7m1m/s5m3djbz7p5Wll5/\nOgvmjP3AmCEM2SdVVeuBTwCISD5wlao2i0gdcO6AY1eNanWN2+zSojEjdNddd7F+/XrWrl3LqlWr\nuOSSS1i/fj01NW6AytKlSyktLaWjo4PTTz+dq666irKysn7vsXnzZh577DEefPBBrr76ap566ikW\nL1486rUm/l/vNJOT6WduVSFzq/oP4lRV9rZ2sbUhGsZcMFtX18wzb+0i9m5NkwuzmVWRR0VBFrmZ\nGeRl+snNGvCcmUF+Vga5WX7yMjPIzfSTl+WeszJ8DDWNWk84wu5mL0Q1d1Df1MnOmEBV39RJW1eo\n3zEBvzClKIeq4mw+MLuMqcU5VBZms6u5g3V1zSx/azePveau1mRm+Jg7pZCTq4s4sbqYk6uLmFWR\njz8BrXuqSnNHDxl+H3mZ/iH/bNJZR3eYjbta+gWszXvbCEfcX9Di3AAnVBXxuXNmMaUoO8HVAjF9\nUnEtWNcAi2J3EJFy3MCfCHArsNTb9BzwbzGd5y/wto8OVXd5cdrAq53GJLHDtEiNlzPOOKM3cAH8\n+Mc/5re//S0AO3bsYPPmzQeFrpqaGubNmwfAaaedxvbt28ekNgtdE4SIUFmYTWVhNh+c3f9u5509\nYd7bf4DahjZq97X3BrO1O5po7wpzoDvEgZhWsqH4feJCWGb/UJab6ae5o4f6pk72trpWqlileZlU\nFWczsyyPD84uZ2pxDlXFLmRNLc6hPD/rsJdEVZX3gwd4s66Zt+qaeLOumd+sqePhV94DIC/Tz/FT\ni/oFsemluSMKQdFLnLuaO9nT3OmeW9zz7pZOdnvP0TsU+ATyszIozAlQkB2gIDuDwuwAhdkZbjnH\nrSvIDlCYHV3uW1+YHYgr1CaD9q4QG+r7Atb6+ma27G3r/XtRlpfJCVOL+OhxkzhxahHHVxVRXZIz\nob57nH1SzwXuFBHFXV78sndsUES+iwtuAHeMap/U6A3TraXLmFGVl9d3j+VVq1bxpz/9iVdeeYXc\n3FzOPfdcOjsPnqkgKyurd9nv99PRMTaTp1voSgLZAT/HTC7gmMkFh9wnElE6esK0d4c40OU9d4dp\n7xrwHLt9wH772ropyM7gnDnlVBXnMLU42wtVOVQV5Yy407+IMKMsjxlleVx2sruxbzii1Da09Qti\nD7/yHt2hbQAU5QS8y5JFnDi1mJOnFTG5MBsRobMn3BuaYp93NXewu6WL3c0dNLR2HRQeMzN8TCly\nAfeU6cVMLsxmUmE24UiE1s4QrZ0hWjp6aOkM0drZw86mDt7p7PG29Rz0fgNl+n29YcwnghIdeAGK\nG2Sh3mAMt82tj3jrie5D36CM6L4oZGf6KcjKIC8rg7wsP/lZrlUzb8Bz73J2BvlZrqUzL9PVlZeV\n0e/ybktnDxt2trCh3rVerd/ZTO2+9t4W1kkFWZwwtYiLTpjCCVWFnFjd999hooujT+qTuDtpDHbs\nUvpavkZX0P0dt9BlzMgUFBTQ2to66Lbm5mZKSkrIzc3lnXfe4dVXXx3n6vqz0JUifD7x/hHOgENn\nswnH7xPmVBYwp7KATxzzeowAAAZiSURBVJ7mRnB1hyK8u6eVdXXNrKtrYl1dMz/9S23vJazy/EzC\nEaXxQM9B71eQncHkwmwmF2Vz9KQKphRlM7koh8lFWUwuzGFyUTYluYEjDguqSnt3mNbOHlo6XAhr\n7QzR0tkX0mLXR1T7BmXggmfvc+86egdgQN/ADCF2n+h2d4mvrStEe1eI9q5w76Xe9q4QbV0huuK8\nr2hmho/8rAwy/T52x8xRN6UomxOmFnHZyVM5sbqQ/9ve/YVWWcdxHH9/3ObOVJzmynLrj5GsbBhJ\n1GoQUV6sP2Q3QUUh0WV/LJKobrrtIqIuIgmzgtQIC5LI/lBBd1FZ1MwisdKl5VqYIZSa3y7Os7Hm\n2dTtOed3nu3zgsM55zfG+ezZ9j3f8zy/3/N0LWrljLl1cahwahk6XYQvAWQ2KQsWLKCnp4euri5a\nWlpYuHDh8Nd6e3tZu3Yty5Yto7Ozk+7u7oRJ3XRZHZrZOIOu9la62lu544ry8vu/j5TnEn295wDb\n9x6kuWlG1ly1DO+1OrO1xJwqLzKQNLwX6azWqr7UhB3599hwA3bon3KDNrIpO5Td/sru/z5yjMVt\ns7l40Vy62ltpm9N84hexyZu9ADpvgPnnpk5iVngbN26sON7c3MzWrVsrfm1o3lZbWxt9fX3D42vW\nrMk93xA3XVYIpaYGlp8zn+Xn5HtC8KmoqWEG82bNZN6smamj2HguWFG+mdm04TX7ZmZmZjXgpsvM\nzMwmJeLkzwlcVHn8jG66zMzMbMJKpRKDg4NTuvGKCAYHBymVJreoyHO6zMzMbMI6Ojro7+9nYGAg\ndZSqKpVKdHRM7jqpbrrMzMxswpqamv53Bngbmw8vmpmZmdWAmy4zMzOzGnDTZWZmZlYDqrfVBpIG\ngJ9P4VvagN+rFCdPzpkv58xX6pznRsTpCV8/N6dYw1Jv95PlnPlyznylznnS9avumq5TJenziLgs\ndY4Tcc58OWe+ipJzqinKdnfOfDlnvoqSE3x40czMzKwm3HSZmZmZ1cBUaLpeSB3gJDlnvpwzX0XJ\nOdUUZbs7Z76cM19FyVn8OV1mZmZmRTAV9nSZmZmZ1T03XWZmZmY1UNimS1KvpO8l7ZT0aOo8lUg6\nW9LHknZI2i5pdepM45HUIOlLSW+nzjIWSfMkbZb0XbZdr0ydqRJJD2W/8z5JmyRN7tL0OZG0XtJ+\nSX0jxk6T9IGkH7L7+SkzTheuYflzDcuPa1h1FLLpktQAPAdcDywFbpe0NG2qio4CD0fERUA3cG+d\n5hyyGtiROsQJPAu8GxEXApdQh3kltQMPAJdFRBfQANyWNtWwl4HeUWOPAh9GxBLgw+y5VZFrWNW4\nhuXANax6Ctl0AZcDOyNiV0QcBl4DVibOdJyI2BcR27LHf1H+52pPm6oySR3AjcC61FnGImkucDXw\nIkBEHI6IA2lTjakRaJHUCMwC9ibOA0BEfAL8MWp4JfBK9vgV4JaahpqeXMNy5hqWO9ewKihq09UO\n7BnxvJ86LQRDJJ0HXAp8mjbJmJ4BHgGOpQ4yjvOBAeCl7BDCOkmzU4caLSJ+AZ4CdgP7gD8j4v20\nqca1MCL2QflNFjgjcZ7pwDUsf65hOXENq56iNl2qMFa3576QNAd4A3gwIg6mzjOapJuA/RHxReos\nJ9AILAeej4hLgUPU4W7kbD7BSmAxsAiYLenOtKmszriG5cg1LF+uYdVT1KarHzh7xPMO6mTX52iS\nmigXqw0R8WbqPGPoAW6W9BPlwxzXSno1baSK+oH+iBj6pL2ZcgGrNyuAHyNiICKOAG8CVyXONJ7f\nJJ0FkN3vT5xnOnANy5drWL5cw6qkqE3XZ8ASSYslzaQ8wW9L4kzHkSTKx+53RMTTqfOMJSIei4iO\niDiP8rb8KCLq7lNNRPwK7JHUmQ1dB3ybMNJYdgPdkmZlfwPXUYeTZUfYAqzKHq8C3kqYZbpwDcuR\na1juXMOqpDF1gImIiKOS7gPeo7yqYn1EbE8cq5Ie4C7gG0lfZWOPR8Q7CTMV3f3AhuyNahdwd+I8\nx4mITyVtBrZRXv31JXVymQpJm4BrgDZJ/cATwJPA65LuoVxsb02XcHpwDZvWXMMmoeg1zJcBMjMz\nM6uBoh5eNDMzMysUN11mZmZmNeCmy8zMzKwG3HSZmZmZ1YCbLjMzM7MacNNlZmZmVgNuuszMzMxq\n4D8Y3obWJvWiagAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f07fbfd3e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_logs(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/anaconda3/envs/dsretreat-s/lib/python3.6/site-packages/ipykernel_launcher.py:47: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1..., padding=\"valid\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "32\n",
      "3\n",
      "48\n",
      "3\n",
      "64\n",
      "1600\n",
      "256\n",
      "256\n",
      "128\n",
      "128\n",
      "10\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/anaconda3/envs/dsretreat-s/lib/python3.6/site-packages/keras/models.py:848: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "4s - loss: 0.3612 - acc: 0.8835 - val_loss: 0.0643 - val_acc: 0.9784\n",
      "3\n",
      "32\n",
      "3\n",
      "48\n",
      "3\n",
      "64\n",
      "1600\n",
      "256\n",
      "256\n",
      "128\n",
      "128\n",
      "10\n",
      "[-0.01283848 -0.0096377   0.00345578 -0.01137695 -0.01514366 -0.00328854\n",
      "  0.01058243  0.01730751  0.01355767  0.0142025  -0.00274067 -0.01450866\n",
      " -0.00995566 -0.00566131  0.00257753 -0.00998909 -0.00381539 -0.01798826\n",
      " -0.01094208 -0.00217533 -0.01895252 -0.01128844 -0.01546262 -0.01225316\n",
      "  0.00159848  0.01442088 -0.0005675  -0.01061232 -0.01811947  0.00363405\n",
      " -0.01304261 -0.00589229  0.00845028 -0.00878603 -0.00601868 -0.0125191\n",
      "  0.00120062 -0.02979659  0.01469032 -0.02512162  0.00069411 -0.01075198\n",
      "  0.00215612 -0.00776287  0.01700664 -0.00090379 -0.01758654 -0.0063515 ]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "3s - loss: 0.0966 - acc: 0.9707 - val_loss: 0.0355 - val_acc: 0.9890\n",
      "3\n",
      "32\n",
      "3\n",
      "48\n",
      "3\n",
      "64\n",
      "1600\n",
      "256\n",
      "256\n",
      "128\n",
      "128\n",
      "10\n",
      "[ -1.02270730e-02  -7.51820812e-03   2.79585808e-03  -1.33545818e-02\n",
      "  -1.32786278e-02  -6.76427595e-03   1.34722833e-02   1.24500282e-02\n",
      "   1.50732603e-02   1.40018063e-02  -7.84355961e-03  -1.30186100e-02\n",
      "  -1.27647966e-02   5.72900695e-04  -7.26111321e-05  -1.03380140e-02\n",
      "   8.48039426e-03  -1.52221471e-02  -1.47295408e-02   7.31891952e-03\n",
      "  -1.77776366e-02  -1.08456574e-02  -1.28965545e-02  -1.15232877e-02\n",
      "  -3.89207643e-03   1.62899699e-02  -4.09964565e-03  -7.12801469e-03\n",
      "  -2.16331463e-02   4.87033837e-03  -8.81533138e-03  -3.56157846e-03\n",
      "   6.19665720e-03  -4.40724799e-03  -6.12534676e-03  -1.05870226e-02\n",
      "   2.22912920e-03  -3.03679705e-02   1.39958523e-02  -1.83623824e-02\n",
      "   8.61034729e-03  -1.19608063e-02   2.62773829e-03  -5.87050198e-03\n",
      "   1.72989387e-02  -5.07326005e-03  -1.93303525e-02  -7.75897596e-03]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "4s - loss: 0.0684 - acc: 0.9788 - val_loss: 0.0297 - val_acc: 0.9907\n",
      "3\n",
      "32\n",
      "3\n",
      "48\n",
      "3\n",
      "64\n",
      "1600\n",
      "256\n",
      "256\n",
      "128\n",
      "128\n",
      "10\n",
      "[ -6.07489049e-03   2.93638790e-03   4.12346981e-03  -5.86767914e-03\n",
      "  -1.26680573e-02  -7.31691020e-03   9.54989903e-03   7.81618617e-03\n",
      "   1.43869631e-02   1.61368083e-02  -1.01534279e-04  -1.20434901e-02\n",
      "  -6.18674932e-03  -7.22509623e-03   3.10059311e-03  -1.50813977e-03\n",
      "   2.05336101e-02  -1.61338709e-02  -1.81858093e-02   3.38237878e-05\n",
      "  -8.92891828e-03  -1.35836340e-02  -2.01418791e-02  -1.18896039e-02\n",
      "  -4.89954883e-03   2.01745015e-02  -1.31001743e-03  -5.56542678e-03\n",
      "  -1.94252022e-02   7.46764801e-03  -6.55814353e-03  -4.49438440e-03\n",
      "   2.70906975e-03   4.78728703e-04   4.60062380e-04  -1.42530203e-02\n",
      "   3.97393858e-04  -3.40984166e-02   1.22334249e-02  -1.59156173e-02\n",
      "   1.44096371e-02  -1.04189869e-02  -2.61854590e-03  -4.91746841e-03\n",
      "   2.19694264e-02  -4.37334878e-03  -1.71753932e-02  -1.26347737e-02]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "3s - loss: 0.0552 - acc: 0.9831 - val_loss: 0.0270 - val_acc: 0.9907\n",
      "3\n",
      "32\n",
      "3\n",
      "48\n",
      "3\n",
      "64\n",
      "1600\n",
      "256\n",
      "256\n",
      "128\n",
      "128\n",
      "10\n",
      "[ -1.45102106e-03  -8.13257531e-04  -3.65900225e-04  -6.44895481e-03\n",
      "  -1.16111385e-02  -1.16994474e-02   3.92453326e-03   5.81888948e-04\n",
      "   9.87826101e-03   1.50769772e-02  -4.86553041e-03  -1.21669350e-02\n",
      "  -6.41590916e-03  -1.14732524e-02  -6.67486922e-04  -5.24351746e-03\n",
      "   2.22562831e-02  -2.43232176e-02  -1.80472080e-02   1.03466995e-02\n",
      "  -6.39060698e-03  -1.23623060e-02  -9.00608860e-03  -1.37308389e-02\n",
      "  -9.18242731e-05   1.59146395e-02   3.50979948e-03  -8.25033581e-04\n",
      "  -2.46688221e-02   8.31385888e-03  -6.19121501e-03  -1.54629210e-03\n",
      "   3.84628912e-03   1.06299808e-02   2.06935429e-03  -5.28286165e-03\n",
      "   2.24256725e-03  -2.88922880e-02   1.30980471e-02  -1.75388157e-02\n",
      "   9.34365019e-03  -1.59480311e-02   1.43276097e-03  -1.72024942e-04\n",
      "   1.96233969e-02  -8.58345348e-03  -1.48175275e-02  -1.49046825e-02]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "4s - loss: 0.0486 - acc: 0.9850 - val_loss: 0.0224 - val_acc: 0.9914\n",
      "3\n",
      "32\n",
      "3\n",
      "48\n",
      "3\n",
      "64\n",
      "1600\n",
      "256\n",
      "256\n",
      "128\n",
      "128\n",
      "10\n",
      "[ 0.00197273 -0.00137214 -0.00138472 -0.00538562 -0.01496948 -0.01349387\n",
      "  0.00601595 -0.00104192  0.00188813  0.01017899 -0.00922927 -0.02655228\n",
      " -0.0019325  -0.00638211  0.00362021 -0.00814553  0.0227429  -0.01770341\n",
      " -0.01863988  0.01454394 -0.00545512 -0.00787422 -0.00424415 -0.0150809\n",
      "  0.00293099  0.02057518 -0.0020862   0.00215871 -0.02847814  0.00723778\n",
      "  0.00056708 -0.00539555 -0.00270862  0.01424     0.00658456 -0.00829131\n",
      " -0.00091866 -0.02865236  0.01787285 -0.01759451  0.01265382 -0.00326323\n",
      " -0.00329695  0.00431769  0.02244389 -0.001242   -0.01565051 -0.0126297 ]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "4s - loss: 0.0420 - acc: 0.9869 - val_loss: 0.0235 - val_acc: 0.9920\n",
      "3\n",
      "32\n",
      "3\n",
      "48\n",
      "3\n",
      "64\n",
      "1600\n",
      "256\n",
      "256\n",
      "128\n",
      "128\n",
      "10\n",
      "[  6.35901047e-03  -6.95166644e-04   1.24266371e-05  -8.28517694e-03\n",
      "  -1.02875968e-02  -8.85841809e-03   1.37827275e-02  -1.79798738e-03\n",
      "   4.06005653e-03   5.50988223e-03  -9.25314706e-03  -1.88227519e-02\n",
      "   1.38782023e-03  -2.75313738e-03   1.09761944e-02  -8.10402911e-03\n",
      "   2.37963181e-02  -1.90178379e-02  -7.70710455e-03   7.94358831e-03\n",
      "  -3.60843772e-03  -1.05772242e-02  -2.42430717e-03  -2.26968471e-02\n",
      "  -5.42718638e-03   1.29610617e-02   2.01308471e-03   7.60237174e-03\n",
      "  -3.00096292e-02   9.26666334e-03  -1.21014332e-03   2.25677417e-04\n",
      "  -1.96545664e-03   8.14626552e-03   1.44079165e-03  -7.94165023e-03\n",
      "   2.33961851e-03  -2.91840006e-02   1.54200960e-02  -2.25811023e-02\n",
      "   2.34072283e-02  -8.50521587e-03   2.95034377e-03   7.30088213e-03\n",
      "   2.34439671e-02  -1.77205366e-03  -8.74470361e-03  -1.78053621e-02]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "3s - loss: 0.0384 - acc: 0.9883 - val_loss: 0.0211 - val_acc: 0.9923\n",
      "3\n",
      "32\n",
      "3\n",
      "48\n",
      "3\n",
      "64\n",
      "1600\n",
      "256\n",
      "256\n",
      "128\n",
      "128\n",
      "10\n",
      "[ 0.00665979 -0.00635386 -0.00034372 -0.00341912 -0.0110148  -0.01664504\n",
      "  0.01456446 -0.003042    0.00351748  0.00735855 -0.00536248 -0.01730529\n",
      "  0.00450298 -0.00379876  0.00941065 -0.00681063  0.02111629 -0.0122674\n",
      " -0.01861721  0.00707664 -0.00447893 -0.00159343 -0.00745164 -0.01448588\n",
      "  0.00280964  0.01463107  0.00724757  0.00270507 -0.02699869  0.00886914\n",
      " -0.0014802  -0.00076368 -0.00065657  0.01132966  0.00452939 -0.00075804\n",
      " -0.00327245 -0.02846598  0.02598295 -0.01209681  0.0217979  -0.01188045\n",
      "  0.00409005  0.00177444  0.02396208  0.00318663 -0.00722152 -0.01472977]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "3s - loss: 0.0345 - acc: 0.9896 - val_loss: 0.0189 - val_acc: 0.9934\n",
      "3\n",
      "32\n",
      "3\n",
      "48\n",
      "3\n",
      "64\n",
      "1600\n",
      "256\n",
      "256\n",
      "128\n",
      "128\n",
      "10\n",
      "[ 0.01232835  0.00324846 -0.00185522  0.00661979 -0.01083812 -0.01009141\n",
      "  0.01885164 -0.00329875  0.00685697  0.00184848 -0.00394437 -0.01339882\n",
      "  0.00177528 -0.00209117  0.01280407 -0.00072434  0.03593338 -0.01050667\n",
      " -0.0134292   0.0133648   0.00154812 -0.00359021 -0.0009079  -0.01483877\n",
      "  0.0092364   0.01161191  0.00924821  0.00676979 -0.02324959  0.00759341\n",
      "  0.00409617  0.0022502  -0.00758944  0.0241983   0.01838291  0.00642934\n",
      " -0.0058735  -0.01801523  0.01559638 -0.0113047   0.01952439 -0.00535846\n",
      "  0.00680728 -0.0001859   0.02184282 -0.00793179 -0.00868679 -0.01246327]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "3s - loss: 0.0316 - acc: 0.9903 - val_loss: 0.0222 - val_acc: 0.9928\n",
      "3\n",
      "32\n",
      "3\n",
      "48\n",
      "3\n",
      "64\n",
      "1600\n",
      "256\n",
      "256\n",
      "128\n",
      "128\n",
      "10\n",
      "[ 0.01143054  0.00314094 -0.00204252  0.00339033 -0.00725491 -0.0156555\n",
      "  0.03450222 -0.01041861  0.0041658  -0.00040379  0.00465774 -0.01949572\n",
      " -0.00249287 -0.0022224   0.0149292  -0.00307633  0.03098169 -0.00782302\n",
      " -0.0119979   0.01801802  0.00031595  0.00317285  0.00085996 -0.01334755\n",
      "  0.0088393   0.01376549  0.0073451   0.00889944 -0.02275947  0.00707531\n",
      "  0.00309114  0.00220803 -0.00073502  0.01446874  0.02082651  0.00111608\n",
      " -0.00067209 -0.02421687  0.02790305 -0.00462257  0.02960454 -0.0083288\n",
      "  0.00762163  0.00351417  0.0225076   0.0036387  -0.00882003 -0.01064603]\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "3s - loss: 0.0287 - acc: 0.9912 - val_loss: 0.0174 - val_acc: 0.9943\n",
      "784\n",
      "30\n",
      "30\n",
      "10\n",
      "[-1.41171479 -0.99935663 -1.09539223 -1.30302477 -1.29974461 -1.27251983\n",
      " -1.33540905 -0.8953051  -1.70241404 -1.25507939]\n",
      "Test score: 0.0174385598524\n",
      "Test accuracy: 0.9943\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "batch_size = 256\n",
    "nb_classes = 10\n",
    "nb_epoch = 30\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "# number of convolutional filters to use                                  \n",
    "nb_filters = 32     \n",
    "nb_filters2 = 48\n",
    "nb_filters3 = 64\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "# convolution kernel size\n",
    "kernel_size = (3, 3)\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)                                                             \n",
    "                                                                               \n",
    "model_ = Sequential()                                                          \n",
    "                                                                               \n",
    "model_.add(Conv2D(nb_filters, (kernel_size[0], kernel_size[1]),           \n",
    "                            border_mode='valid',                               \n",
    "                                                    input_shape=input_shape))  \n",
    "model_.add(Activation('relu'))                                                 \n",
    "model_.add(Conv2D(nb_filters2, (kernel_size[0], kernel_size[1])))          \n",
    "model_.add(Activation('relu'))                                                 \n",
    "model_.add(MaxPooling2D(pool_size=pool_size))                                  \n",
    "model_.add(Dropout(0.25))                                                      \n",
    "model_.add(Conv2D(nb_filters3, (kernel_size[0], kernel_size[1])))         \n",
    "model_.add(Activation('relu'))                                                 \n",
    "model_.add(MaxPooling2D(pool_size=pool_size))                                  \n",
    "model_.add(Dropout(0.25))                                                      \n",
    "                                                                               \n",
    "                                                                               \n",
    "model_.add(Flatten())                                                          \n",
    "model_.add(Dense(256))                                                         \n",
    "model_.add(Activation('relu'))                                                 \n",
    "model_.add(Dropout(0.5))                                                       \n",
    "                                                                               \n",
    "model_.add(Dense(128))                                                         \n",
    "model_.add(Activation('relu'))                                                 \n",
    "                                                                               \n",
    "model_.add(Dense(nb_classes))                                                  \n",
    "model_.add(Activation('softmax'))                                              \n",
    "                                                                               \n",
    "model_.compile(loss='categorical_crossentropy',                                \n",
    "                      optimizer='Adam',                                   \n",
    "                      metrics=['accuracy'])                      \n",
    "                                                                               \n",
    "#history_ = model_.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "#                  verbose=2, validation_data=(X_test, Y_test))  \n",
    "\n",
    "for i in range(10):\n",
    "    score = model_.evaluate(X_test, Y_test, verbose=2) \n",
    "    weights = model_.get_weights()\n",
    "    for weight in weights:\n",
    "        print(len(weight))\n",
    "    print(weights[3])\n",
    "\n",
    "    model_.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=1,\n",
    "                 verbose=2, validation_data=(X_test, Y_test))  \n",
    "        \n",
    "\n",
    "score = model_.evaluate(X_test, Y_test, verbose=2) \n",
    "weights = model.get_weights()\n",
    "for weight in weights:\n",
    "    print(len(weight))\n",
    "print(weights[3])\n",
    "\n",
    "print('Test score:', score[0])                                                 \n",
    "print('Test accuracy:', score[1])                                              \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Conv2D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
