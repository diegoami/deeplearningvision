{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib \n",
    "matplotlib.use('Agg') \n",
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## looking at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import array_to_img\n",
    "\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 32, 32\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "list_concepts = ['airplane', \n",
    "                 'automobile', \n",
    "                 'bird', \n",
    "                 'cat', \n",
    "                 'deer', \n",
    "                 'dog', \n",
    "                 'frog', \n",
    "                 'horse', \n",
    "                 'ship', \n",
    "                 'truck']\n",
    "\n",
    "nb_classes = len(list_concepts)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47527\n",
      "[8] ship\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAHwElEQVR4nC2WvY5dSRVGv/1TVeec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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F1FF12515C0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = random.randint(0, len(y_train))\n",
    "print(i,) \n",
    "print(y_train[i], list_concepts[y_train[i][0]])\n",
    "array_to_img(X_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import History, ModelCheckpoint\n",
    "\n",
    "class PlotHistory(History):\n",
    "    def __init__(self, file_name='history.png'):\n",
    "        History.__init__(self)\n",
    "        self.file_name = file_name\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        History.on_epoch_end(self, epoch, logs)\n",
    "        self.plot_logs()\n",
    "    def plot_logs(self):\n",
    "        evaluation_cost = self.history['val_loss']\n",
    "        evaluation_accuracy = self.history['val_acc']\n",
    "        training_cost = self.history['loss']\n",
    "        training_accuracy = self.history['acc']\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "        f.set_figwidth(10)\n",
    "        ax1.plot(evaluation_cost,label= 'test')\n",
    "        ax1.plot(training_cost, label='train')\n",
    "        ax1.set_title('Cost')\n",
    "        ax1.legend()\n",
    "        ax2.plot(evaluation_accuracy, label='test')\n",
    "        ax2.plot(training_accuracy, label='train')\n",
    "        ax2.set_title('Accuracy')\n",
    "        ax2.legend(loc='lower right')\n",
    "        f.savefig(self.file_name)\n",
    "        plt.close(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/anaconda3/envs/dsretreat-s/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(32, 32, 3..., padding=\"valid\")`\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/diego/anaconda3/envs/dsretreat-s/lib/python3.6/site-packages/keras/models.py:848: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "3s - loss: 2.0370 - acc: 0.2625 - val_loss: 1.8833 - val_acc: 0.3434\n",
      "Epoch 2/40\n",
      "2s - loss: 1.8015 - acc: 0.3673 - val_loss: 1.7816 - val_acc: 0.3785\n",
      "Epoch 3/40\n",
      "2s - loss: 1.7155 - acc: 0.4030 - val_loss: 1.7559 - val_acc: 0.3768\n",
      "Epoch 4/40\n",
      "2s - loss: 1.6597 - acc: 0.4261 - val_loss: 1.6392 - val_acc: 0.4247\n",
      "Epoch 5/40\n",
      "2s - loss: 1.6051 - acc: 0.4434 - val_loss: 1.5939 - val_acc: 0.4455\n",
      "Epoch 6/40\n",
      "2s - loss: 1.5573 - acc: 0.4609 - val_loss: 1.5199 - val_acc: 0.4774\n",
      "Epoch 7/40\n",
      "2s - loss: 1.5187 - acc: 0.4748 - val_loss: 1.5054 - val_acc: 0.4648\n",
      "Epoch 8/40\n",
      "2s - loss: 1.4833 - acc: 0.4878 - val_loss: 1.5974 - val_acc: 0.4393\n",
      "Epoch 9/40\n",
      "2s - loss: 1.4576 - acc: 0.4974 - val_loss: 1.4594 - val_acc: 0.4916\n",
      "Epoch 10/40\n",
      "2s - loss: 1.4314 - acc: 0.5055 - val_loss: 1.4188 - val_acc: 0.5108\n",
      "Epoch 11/40\n",
      "2s - loss: 1.4093 - acc: 0.5145 - val_loss: 1.4631 - val_acc: 0.4936\n",
      "Epoch 12/40\n",
      "2s - loss: 1.3881 - acc: 0.5209 - val_loss: 1.4231 - val_acc: 0.5048\n",
      "Epoch 13/40\n",
      "2s - loss: 1.3666 - acc: 0.5284 - val_loss: 1.4145 - val_acc: 0.5082\n",
      "Epoch 14/40\n",
      "2s - loss: 1.3552 - acc: 0.5334 - val_loss: 1.3665 - val_acc: 0.5229\n",
      "Epoch 15/40\n",
      "2s - loss: 1.3331 - acc: 0.5425 - val_loss: 1.4537 - val_acc: 0.4975\n",
      "Epoch 16/40\n",
      "2s - loss: 1.3195 - acc: 0.5458 - val_loss: 1.3349 - val_acc: 0.5365\n",
      "Epoch 17/40\n",
      "2s - loss: 1.3090 - acc: 0.5507 - val_loss: 1.3552 - val_acc: 0.5260\n",
      "Epoch 18/40\n",
      "2s - loss: 1.2953 - acc: 0.5546 - val_loss: 1.3238 - val_acc: 0.5377\n",
      "Epoch 19/40\n",
      "2s - loss: 1.2804 - acc: 0.5588 - val_loss: 1.3567 - val_acc: 0.5312\n",
      "Epoch 20/40\n",
      "2s - loss: 1.2701 - acc: 0.5632 - val_loss: 1.3342 - val_acc: 0.5405\n",
      "Epoch 21/40\n",
      "2s - loss: 1.2527 - acc: 0.5721 - val_loss: 1.3046 - val_acc: 0.5521\n",
      "Epoch 22/40\n",
      "2s - loss: 1.2434 - acc: 0.5748 - val_loss: 1.2792 - val_acc: 0.5587\n",
      "Epoch 23/40\n",
      "2s - loss: 1.2347 - acc: 0.5765 - val_loss: 1.2659 - val_acc: 0.5609\n",
      "Epoch 24/40\n",
      "2s - loss: 1.2176 - acc: 0.5819 - val_loss: 1.2847 - val_acc: 0.5590\n",
      "Epoch 25/40\n",
      "2s - loss: 1.2028 - acc: 0.5899 - val_loss: 1.2883 - val_acc: 0.5546\n",
      "Epoch 26/40\n",
      "2s - loss: 1.1935 - acc: 0.5928 - val_loss: 1.4066 - val_acc: 0.5250\n",
      "Epoch 27/40\n",
      "2s - loss: 1.1830 - acc: 0.5942 - val_loss: 1.2692 - val_acc: 0.5567\n",
      "Epoch 28/40\n",
      "2s - loss: 1.1726 - acc: 0.6007 - val_loss: 1.2828 - val_acc: 0.5514\n",
      "Epoch 29/40\n",
      "2s - loss: 1.1595 - acc: 0.6020 - val_loss: 1.2417 - val_acc: 0.5676\n",
      "Epoch 30/40\n",
      "2s - loss: 1.1493 - acc: 0.6056 - val_loss: 1.2177 - val_acc: 0.5766\n",
      "Epoch 31/40\n",
      "2s - loss: 1.1397 - acc: 0.6111 - val_loss: 1.2819 - val_acc: 0.5555\n",
      "Epoch 32/40\n",
      "2s - loss: 1.1257 - acc: 0.6155 - val_loss: 1.3069 - val_acc: 0.5504\n",
      "Epoch 33/40\n",
      "2s - loss: 1.1206 - acc: 0.6168 - val_loss: 1.2571 - val_acc: 0.5709\n",
      "Epoch 34/40\n",
      "2s - loss: 1.1117 - acc: 0.6185 - val_loss: 1.2122 - val_acc: 0.5830\n",
      "Epoch 35/40\n",
      "2s - loss: 1.1001 - acc: 0.6247 - val_loss: 1.2244 - val_acc: 0.5662\n",
      "Epoch 36/40\n",
      "2s - loss: 1.0898 - acc: 0.6278 - val_loss: 1.1917 - val_acc: 0.5931\n",
      "Epoch 37/40\n",
      "2s - loss: 1.0824 - acc: 0.6281 - val_loss: 1.1708 - val_acc: 0.5929\n",
      "Epoch 38/40\n",
      "2s - loss: 1.0725 - acc: 0.6355 - val_loss: 1.1796 - val_acc: 0.5939\n",
      "Epoch 39/40\n",
      "2s - loss: 1.0610 - acc: 0.6379 - val_loss: 1.1937 - val_acc: 0.5829\n",
      "Epoch 40/40\n",
      "2s - loss: 1.0601 - acc: 0.6393 - val_loss: 1.1723 - val_acc: 0.5870\n",
      "Test score: 1.17234352493\n",
      "Test accuracy: 0.587\n"
     ]
    }
   ],
   "source": [
    "## magic numbers:\n",
    "batch_size = 128\n",
    "nb_epoch = 40\n",
    "\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "# convolution kernel size\n",
    "kernel_size = (3, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],\n",
    "                        border_mode='valid',\n",
    "                        input_shape=input_shape))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "plot_history_callback = PlotHistory('cifar10.png')\n",
    "save_snapshots = ModelCheckpoint('cifar10.h5')\n",
    "\n",
    "history = model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "          verbose=2, validation_data=(X_test, Y_test), \n",
    "                    callbacks=[plot_history_callback, save_snapshots])\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## looking at our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "import io\n",
    "import numpy\n",
    "def load_photo_from_url(image_url, target_size=None, time_out_image_downloading=1):\n",
    "    response = requests.get(image_url, timeout=time_out_image_downloading)\n",
    "    image = Image.open(io.BytesIO(response.content))\n",
    "    image = image.resize((target_size[1], target_size[0]))\n",
    "    img_array = img_to_array(image) / 255.0\n",
    "    img_array = img_array.reshape((1,) + img_array.shape)\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ship'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://cdn.eyeem.com/thumb/898895b99f70bff29986de9133516b6a781f5cd0-1437676159/w/450'\n",
    "predictions = model.predict(load_photo_from_url(url,(32,32)))\n",
    "list_concepts[numpy.argmax(predictions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/anaconda3/envs/dsretreat-s/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(32, 32, 3..., padding=\"valid\")`\n",
      "  app.launch_new_instance()\n",
      "/home/diego/anaconda3/envs/dsretreat-s/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\")`\n",
      "/home/diego/anaconda3/envs/dsretreat-s/lib/python3.6/site-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\")`\n",
      "/home/diego/anaconda3/envs/dsretreat-s/lib/python3.6/site-packages/ipykernel_launcher.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), padding=\"same\")`\n",
      "/home/diego/anaconda3/envs/dsretreat-s/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), padding=\"same\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/anaconda3/envs/dsretreat-s/lib/python3.6/site-packages/ipykernel_launcher.py:80: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/home/diego/anaconda3/envs/dsretreat-s/lib/python3.6/site-packages/ipykernel_launcher.py:80: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_data=(array([[[..., verbose=2, steps_per_epoch=390, epochs=50)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10s - loss: 1.3310 - acc: 0.5433 - val_loss: 1.1831 - val_acc: 0.5894\n",
      "Epoch 2/50\n",
      "10s - loss: 1.3085 - acc: 0.5496 - val_loss: 1.1606 - val_acc: 0.5978\n",
      "Epoch 3/50\n",
      "10s - loss: 1.2937 - acc: 0.5552 - val_loss: 1.1433 - val_acc: 0.6111\n",
      "Epoch 4/50\n",
      "10s - loss: 1.2869 - acc: 0.5569 - val_loss: 1.1692 - val_acc: 0.5961\n",
      "Epoch 5/50\n",
      "10s - loss: 1.2846 - acc: 0.5561 - val_loss: 1.1278 - val_acc: 0.6133\n",
      "Epoch 6/50\n",
      "10s - loss: 1.2749 - acc: 0.5608 - val_loss: 1.1816 - val_acc: 0.5894\n",
      "Epoch 7/50\n",
      "10s - loss: 1.2719 - acc: 0.5636 - val_loss: 1.1449 - val_acc: 0.6009\n",
      "Epoch 8/50\n",
      "10s - loss: 1.2593 - acc: 0.5661 - val_loss: 1.1342 - val_acc: 0.6116\n",
      "Epoch 9/50\n",
      "10s - loss: 1.2643 - acc: 0.5620 - val_loss: 1.1119 - val_acc: 0.6242\n",
      "Epoch 10/50\n",
      "10s - loss: 1.2607 - acc: 0.5691 - val_loss: 1.1099 - val_acc: 0.6222\n",
      "Epoch 11/50\n",
      "10s - loss: 1.2455 - acc: 0.5702 - val_loss: 1.1208 - val_acc: 0.6186\n",
      "Epoch 12/50\n",
      "10s - loss: 1.2471 - acc: 0.5732 - val_loss: 1.1486 - val_acc: 0.6048\n",
      "Epoch 13/50\n",
      "10s - loss: 1.2443 - acc: 0.5720 - val_loss: 1.1202 - val_acc: 0.6155\n",
      "Epoch 14/50\n",
      "10s - loss: 1.2376 - acc: 0.5766 - val_loss: 1.1468 - val_acc: 0.6054\n",
      "Epoch 15/50\n",
      "10s - loss: 1.2405 - acc: 0.5752 - val_loss: 1.1131 - val_acc: 0.6214\n",
      "Epoch 16/50\n",
      "10s - loss: 1.2332 - acc: 0.5776 - val_loss: 1.1039 - val_acc: 0.6227\n",
      "Epoch 17/50\n",
      "10s - loss: 1.2347 - acc: 0.5790 - val_loss: 1.1241 - val_acc: 0.6139\n",
      "Epoch 18/50\n",
      "10s - loss: 1.2365 - acc: 0.5762 - val_loss: 1.1071 - val_acc: 0.6222\n",
      "Epoch 19/50\n",
      "10s - loss: 1.2302 - acc: 0.5788 - val_loss: 1.1026 - val_acc: 0.6254\n",
      "Epoch 20/50\n",
      "10s - loss: 1.2312 - acc: 0.5757 - val_loss: 1.1062 - val_acc: 0.6218\n",
      "Epoch 21/50\n",
      "10s - loss: 1.2201 - acc: 0.5792 - val_loss: 1.1190 - val_acc: 0.6180\n",
      "Epoch 22/50\n",
      "10s - loss: 1.2174 - acc: 0.5831 - val_loss: 1.1076 - val_acc: 0.6215\n",
      "Epoch 23/50\n",
      "10s - loss: 1.2232 - acc: 0.5784 - val_loss: 1.1012 - val_acc: 0.6253\n",
      "Epoch 24/50\n",
      "10s - loss: 1.2184 - acc: 0.5837 - val_loss: 1.1047 - val_acc: 0.6196\n",
      "Epoch 25/50\n",
      "10s - loss: 1.2153 - acc: 0.5838 - val_loss: 1.0886 - val_acc: 0.6307\n",
      "Epoch 26/50\n",
      "10s - loss: 1.2128 - acc: 0.5867 - val_loss: 1.1137 - val_acc: 0.6225\n",
      "Epoch 27/50\n",
      "10s - loss: 1.2160 - acc: 0.5805 - val_loss: 1.1630 - val_acc: 0.6021\n",
      "Epoch 28/50\n",
      "10s - loss: 1.2148 - acc: 0.5827 - val_loss: 1.1535 - val_acc: 0.6069\n",
      "Epoch 29/50\n",
      "10s - loss: 1.2133 - acc: 0.5840 - val_loss: 1.0923 - val_acc: 0.6241\n",
      "Epoch 30/50\n",
      "10s - loss: 1.2068 - acc: 0.5828 - val_loss: 1.0978 - val_acc: 0.6239\n",
      "Epoch 31/50\n",
      "10s - loss: 1.2057 - acc: 0.5862 - val_loss: 1.0915 - val_acc: 0.6351\n",
      "Epoch 32/50\n",
      "10s - loss: 1.1977 - acc: 0.5896 - val_loss: 1.0939 - val_acc: 0.6272\n",
      "Epoch 33/50\n",
      "10s - loss: 1.2047 - acc: 0.5869 - val_loss: 1.1606 - val_acc: 0.6177\n",
      "Epoch 34/50\n",
      "10s - loss: 1.2039 - acc: 0.5858 - val_loss: 1.1190 - val_acc: 0.6185\n",
      "Epoch 35/50\n",
      "10s - loss: 1.2112 - acc: 0.5846 - val_loss: 1.0840 - val_acc: 0.6337\n",
      "Epoch 36/50\n",
      "10s - loss: 1.1965 - acc: 0.5911 - val_loss: 1.0877 - val_acc: 0.6298\n",
      "Epoch 37/50\n",
      "10s - loss: 1.1996 - acc: 0.5923 - val_loss: 1.0963 - val_acc: 0.6275\n",
      "Epoch 38/50\n",
      "10s - loss: 1.2044 - acc: 0.5849 - val_loss: 1.1212 - val_acc: 0.6214\n",
      "Epoch 39/50\n",
      "10s - loss: 1.1950 - acc: 0.5897 - val_loss: 1.0863 - val_acc: 0.6296\n",
      "Epoch 40/50\n",
      "10s - loss: 1.1994 - acc: 0.5919 - val_loss: 1.0826 - val_acc: 0.6370\n",
      "Epoch 41/50\n",
      "10s - loss: 1.1945 - acc: 0.5901 - val_loss: 1.0919 - val_acc: 0.6305\n",
      "Epoch 42/50\n",
      "10s - loss: 1.1935 - acc: 0.5921 - val_loss: 1.1187 - val_acc: 0.6274\n",
      "Epoch 43/50\n",
      "10s - loss: 1.1952 - acc: 0.5920 - val_loss: 1.0916 - val_acc: 0.6310\n",
      "Epoch 44/50\n",
      "10s - loss: 1.1885 - acc: 0.5937 - val_loss: 1.0993 - val_acc: 0.6250\n",
      "Epoch 45/50\n",
      "10s - loss: 1.1975 - acc: 0.5913 - val_loss: 1.0713 - val_acc: 0.6359\n",
      "Epoch 46/50\n",
      "10s - loss: 1.2016 - acc: 0.5879 - val_loss: 1.0743 - val_acc: 0.6375\n",
      "Epoch 47/50\n",
      "10s - loss: 1.1915 - acc: 0.5929 - val_loss: 1.0798 - val_acc: 0.6315\n",
      "Epoch 48/50\n",
      "10s - loss: 1.1872 - acc: 0.5942 - val_loss: 1.0971 - val_acc: 0.6313\n",
      "Epoch 49/50\n",
      "10s - loss: 1.1921 - acc: 0.5887 - val_loss: 1.0872 - val_acc: 0.6309\n",
      "Epoch 50/50\n",
      "10s - loss: 1.1890 - acc: 0.5922 - val_loss: 1.1002 - val_acc: 0.6238\n",
      "Test score: 1.10023808994\n",
      "Test accuracy: 0.6238\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "## magic numbers:\n",
    "batch_size = 128\n",
    "nb_epoch = 50\n",
    "\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "# convolution kernel size\n",
    "kernel_size = (3, 3)\n",
    "\n",
    "model_ = Sequential()                                                          \n",
    "                                                                               \n",
    "model_.add(Convolution2D(64, kernel_size[0], kernel_size[1],           \n",
    "                            border_mode='valid',                               \n",
    "                            input_shape=input_shape))    \n",
    "model_.add(Activation('relu')) \n",
    "model_.add(Convolution2D(64, kernel_size[0], kernel_size[1],border_mode='same'))          \n",
    "model_.add(Activation('relu'))                       \n",
    "model_.add(MaxPooling2D(pool_size=pool_size))     \n",
    "model_.add(Dropout(0.3))\n",
    "\n",
    "  \n",
    "model_.add(Convolution2D(128, kernel_size[0], kernel_size[1],border_mode='same'))          \n",
    "model_.add(Activation('relu'))                       \n",
    "model_.add(MaxPooling2D(pool_size=pool_size))                                  \n",
    "model_.add(Dropout(0.4))  \n",
    "\n",
    "model_.add(Convolution2D(256, kernel_size[0], kernel_size[1],border_mode='same'))          \n",
    "model_.add(Activation('relu')) \n",
    "model_.add(MaxPooling2D(pool_size=pool_size))                                  \n",
    "model_.add(Dropout(0.4)) \n",
    "\n",
    "model_.add(Convolution2D(512, kernel_size[0], kernel_size[1],border_mode='same'))          \n",
    "model_.add(Activation('relu')) \n",
    "model_.add(MaxPooling2D(pool_size=pool_size))                                  \n",
    "model_.add(Dropout(0.4))\n",
    "\n",
    "model_.add(Flatten())                                                            \n",
    "model_.add(Dense(512))                                                         \n",
    "model_.add(Activation('relu'))   \n",
    "model_.add(Dropout(0.5))\n",
    "\n",
    "model_.add(Dense(256))                                                         \n",
    "model_.add(Activation('relu'))    \n",
    "                                                                                                          \n",
    "model_.add(Dense(nb_classes))                                                  \n",
    "model_.add(Activation('softmax'))                                              \n",
    "                                                                               \n",
    "model_.compile(loss='categorical_crossentropy',                                \n",
    "                      optimizer='Nadam',                                   \n",
    "                      metrics=['accuracy'])  \n",
    "\n",
    "plot_history_callback = PlotHistory('cifar10.png')\n",
    "save_snapshots = ModelCheckpoint('cifar10.h5')\n",
    "\n",
    "print('Using real-time data augmentation.')\n",
    "# This will do preprocessing and realtime data augmentation:\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "\n",
    "# Compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied).\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "history = model.fit_generator(datagen.flow(X_train, Y_train,\n",
    "                                 batch_size=batch_size),\n",
    "                    samples_per_epoch=X_train.shape[0],\n",
    "                    nb_epoch=nb_epoch,\n",
    "validation_data=(X_test, Y_test), verbose=2)\n",
    "\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/anaconda3/envs/dsretreat-s/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(32, 32, 3..., padding=\"same\")`\n",
      "  after removing the cwd from sys.path.\n",
      "/home/diego/anaconda3/envs/dsretreat-s/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "  \n",
      "/home/diego/anaconda3/envs/dsretreat-s/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/diego/anaconda3/envs/dsretreat-s/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3))`\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/anaconda3/envs/dsretreat-s/lib/python3.6/site-packages/ipykernel_launcher.py:59: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/home/diego/anaconda3/envs/dsretreat-s/lib/python3.6/site-packages/ipykernel_launcher.py:59: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_data=(array([[[..., verbose=2, steps_per_epoch=390, epochs=50)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10s - loss: 2.3030 - acc: 0.0977 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 2/50\n",
      "10s - loss: 2.3028 - acc: 0.0987 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 3/50\n",
      "10s - loss: 2.3027 - acc: 0.0996 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 4/50\n",
      "10s - loss: 2.3027 - acc: 0.0992 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 5/50\n",
      "10s - loss: 2.3027 - acc: 0.0997 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 6/50\n",
      "10s - loss: 2.3027 - acc: 0.0989 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 7/50\n",
      "11s - loss: 2.3027 - acc: 0.0967 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 8/50\n",
      "10s - loss: 2.3027 - acc: 0.0997 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 9/50\n",
      "10s - loss: 2.3027 - acc: 0.0988 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 10/50\n",
      "10s - loss: 2.3027 - acc: 0.0963 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 11/50\n",
      "10s - loss: 2.3027 - acc: 0.0989 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 12/50\n",
      "10s - loss: 2.3027 - acc: 0.0988 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 13/50\n",
      "10s - loss: 2.3027 - acc: 0.0973 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 14/50\n",
      "10s - loss: 2.3027 - acc: 0.0978 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 15/50\n",
      "10s - loss: 2.3027 - acc: 0.0985 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 16/50\n",
      "11s - loss: 2.3027 - acc: 0.0958 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 17/50\n",
      "10s - loss: 2.3027 - acc: 0.0972 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 18/50\n",
      "11s - loss: 2.3027 - acc: 0.0984 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 19/50\n",
      "10s - loss: 2.3027 - acc: 0.0993 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 20/50\n",
      "10s - loss: 2.3027 - acc: 0.0983 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 21/50\n",
      "10s - loss: 2.3027 - acc: 0.0987 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 22/50\n",
      "10s - loss: 2.3027 - acc: 0.0989 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 23/50\n",
      "10s - loss: 2.3027 - acc: 0.0976 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 24/50\n",
      "10s - loss: 2.3027 - acc: 0.0971 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 25/50\n",
      "10s - loss: 2.3027 - acc: 0.0990 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 26/50\n",
      "10s - loss: 2.3027 - acc: 0.0991 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 27/50\n",
      "10s - loss: 2.3027 - acc: 0.0970 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 28/50\n",
      "10s - loss: 2.3027 - acc: 0.0978 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 29/50\n",
      "10s - loss: 2.3027 - acc: 0.0979 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 30/50\n",
      "10s - loss: 2.3027 - acc: 0.0988 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 31/50\n",
      "10s - loss: 2.3027 - acc: 0.0978 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 32/50\n",
      "10s - loss: 2.3027 - acc: 0.0982 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 33/50\n",
      "10s - loss: 2.3027 - acc: 0.0979 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 34/50\n",
      "10s - loss: 2.3027 - acc: 0.0992 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 35/50\n",
      "10s - loss: 2.3027 - acc: 0.0973 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 36/50\n",
      "10s - loss: 2.3027 - acc: 0.0974 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 37/50\n",
      "10s - loss: 2.3027 - acc: 0.0969 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 38/50\n",
      "10s - loss: 2.3027 - acc: 0.0970 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 39/50\n",
      "10s - loss: 2.3027 - acc: 0.1001 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 40/50\n",
      "10s - loss: 2.3027 - acc: 0.0976 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 41/50\n",
      "10s - loss: 2.3027 - acc: 0.0952 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 42/50\n",
      "11s - loss: 2.3027 - acc: 0.0974 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 43/50\n",
      "10s - loss: 2.3027 - acc: 0.0966 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 44/50\n",
      "10s - loss: 2.3027 - acc: 0.0973 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 45/50\n",
      "10s - loss: 2.3027 - acc: 0.0995 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 46/50\n",
      "11s - loss: 2.3027 - acc: 0.0998 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 47/50\n",
      "10s - loss: 2.3027 - acc: 0.0983 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 48/50\n",
      "10s - loss: 2.3027 - acc: 0.0971 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 49/50\n",
      "10s - loss: 2.3027 - acc: 0.0970 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 50/50\n",
      "10s - loss: 2.3027 - acc: 0.0978 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Test score: 2.3025986927\n",
      "Test accuracy: 0.1\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3, border_mode='same',\n",
    "                        input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "\n",
    "print('Using real-time data augmentation.')\n",
    "# This will do preprocessing and realtime data augmentation:\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "\n",
    "# Compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied).\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "history = model.fit_generator(datagen.flow(X_train, Y_train,\n",
    "                                 batch_size=batch_size),\n",
    "                    samples_per_epoch=X_train.shape[0],\n",
    "                    nb_epoch=nb_epoch,\n",
    "validation_data=(X_test, Y_test), verbose=2)\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
